[
  {
    "objectID": "R_basics_packages.html",
    "href": "R_basics_packages.html",
    "title": "R Basics: installing and loading packages",
    "section": "",
    "text": "One of the best features of R is it’s huge library of free and open-source packages. Packages are R’s system of being able to add functions, objects, classes, and data to our session. “Base” R has a lot of functionality already, but for more specialized kinds of analysis or other functions (like graphing), there are many excellent packages to add functionality.\nThe goal of this tutorial is to explain the basics of how this system works, so that you can make the most of the huge ecosystem of great R packages.\n\n\nR has a standard way of creating packages, and there are a number of good tutorials and tools to make it relatively easy to create your own packages. However, most users get by just fine by installing and using packages from freely available repositories.\nThe most common way to get packages is from the official repository called the Comprehensive R Archive Network (CRAN). However, getting a package onto CRAN takes a little time and administrative overhead, so sometimes you may find a package that is hosted elsewhere, like GitHub or the Bioconductor repository.\nWhen you get a package from CRAN, much like when you download R to begin with, you may have to pick a “mirror” – one of many identical sites hosted over the world that provide the service of distributing R code. Depending on your settings, your installation may pick a mirror for you. Either way, when you get a package from CRAN, it’s coming from one of the mirrors, and if you are asked to pick, just pick one that is geographically in a similar region as you are.\n\n\n\nThis couldn’t be simpler (at least, most of the time). There are really just two steps. The installation process is a one-time process. It involves downloading code from CRAN (or somewhere else), and unpacking or “building” the code in a location on your machine where your installation of R can find it. It does this all automatically, so you don’t need to make any decisions here.\nOnce it’s installed, you do NOT need to re-install it, unless you want to download a newer version, or unless you change your base installation version of R (like upgrading from 4.5.0 to 4.5.1).\nLet’s do this now for the main graphing package we will use in this course, ggplot2. Run the code chunk below to install this package, if you don’t already have this package installed.\n\ninstall.packages(\"ggplot2\")\n\n\n\n\nIf you imagine that your installation of R is like your personal workshop for doing data analysis, installing a new package is like going to the hardware store, buying a cool new tool kit, and then coming home and “installing” it into a special drawer in your workbench. Once it’s installed, you don’t need to go back to the store, unless you want a newer version, or unless you are building a new workshop (i.e., working in a new installation of base R).\nBut you do need to get those shiny new tools out of their special drawer when you want to use them. In R, this means you need to load the package during the session you are using it. You only need to load it once, until you start a new session. In other words, “loading” a package is like taking the tool kit out of its drawer so that you can work with those tools. When the session is done, the tools go back into their drawer, so they will need to be loaded again when you start a new session.\nWe do this using the library() function. So after you have installed the ggplot2 package, you can run the following:\n\nlibrary(ggplot2)\n\nIf you get an error message, then this more than likely means the package was not correctly installed.\nSo just to be clear: you only need to run install.packages(\"packagename\") once, in order to download and install a given package, but then you need to load that package with library(packagename) once every session when you want to use something from that package.1\n1 Note also that you use quotes around the package name when installing, but not when you use library()\n\n\nWhen you run install.packages(), it will not only install the package you asked for, but all of the packages that are dependencies of the package you are installing (plus all of the dependencies’ dependencies, and so on). This is great, because it means R’s package system is doing all the work for you to make sure you have everything you need in order to use the package. This is pretty common, and a sign of a healthy programming community, because it shows how package authors frequently build on the work of others.\nHowever, sometimes it means that you are installing a lot of packages at once, and sometimes things can go wrong during the installation process.\nIn general, a lot of stuff gets printed to the console when a package is being installed, but at the very end, if you see a message that an installation “exited with non-zero status”, it means something didn’t quite work right.\nIn order to figure out what to do, you may need to scroll back through all the console print-outs, and see if there are any warnings or error messages.\nThe most common thing that can go wrong is that a package may depend on some other piece of software that isn’t directly managed by R’s package system. For example, if you are on a Windows machine, you will likely need to install the Rtools software at some point. This is additional software that provides some utilities that are common on macOS and Linux systems, but which are not typically part of a normal Windows installation.\nIn this case, Rtools can be found if you go to the r-project site where you downloaded R the first time, and on the page where you can choose to download “base” R, you should see a link a little lower down to download an installer for Rtools.\nIn other cases, depending on the packages you’re installing, you might need some other utilities or programs. But the pattern is the same: if you “exit the installation with a non-zero status”, you should look through the messages to see if it tells you what you’re missing.\nIf you think you’ve addressed the issue, just try re-running install.packages(), to see if you can get through it without any problems. Once you finally get through the process cleanly, you should be all set.\nIf you run into problems with installation of any packages in this course, please ask for help!\nFortunately, package installation in R is usually pretty headache free, and besides the common need for Rtools on Windows, installation problems are usually pretty rare.\n\n\n\nRecent installations of RStudio also try to assist you with the installation process. For example, if you open up a script or notebook, and RStudio notices that it uses packages that you don’t have installed, it will actually display a small pop-up notice at the top of the window to let you know, and if it knows where to find the package (say, on CRAN), it will even give you a link you can click which will run install.packages() for you.\nIn general, I have had a good experience with RStudio making these suggestions. In other words, if RStudio is making a suggestion, it’s typically a good idea to follow it, and just install what it recommends. I have never had “bloatware” kinds of issues by following RStudio’s prompts.\nOf course, as always, you should be aware of what you’re installing, just in case.",
    "crumbs": [
      "Home",
      "Preliminaries",
      "Installing and loading R packages"
    ]
  },
  {
    "objectID": "R_basics_packages.html#where-do-you-get-packages",
    "href": "R_basics_packages.html#where-do-you-get-packages",
    "title": "R Basics: installing and loading packages",
    "section": "",
    "text": "R has a standard way of creating packages, and there are a number of good tutorials and tools to make it relatively easy to create your own packages. However, most users get by just fine by installing and using packages from freely available repositories.\nThe most common way to get packages is from the official repository called the Comprehensive R Archive Network (CRAN). However, getting a package onto CRAN takes a little time and administrative overhead, so sometimes you may find a package that is hosted elsewhere, like GitHub or the Bioconductor repository.\nWhen you get a package from CRAN, much like when you download R to begin with, you may have to pick a “mirror” – one of many identical sites hosted over the world that provide the service of distributing R code. Depending on your settings, your installation may pick a mirror for you. Either way, when you get a package from CRAN, it’s coming from one of the mirrors, and if you are asked to pick, just pick one that is geographically in a similar region as you are.",
    "crumbs": [
      "Home",
      "Preliminaries",
      "Installing and loading R packages"
    ]
  },
  {
    "objectID": "R_basics_packages.html#how-do-you-get-packages",
    "href": "R_basics_packages.html#how-do-you-get-packages",
    "title": "R Basics: installing and loading packages",
    "section": "",
    "text": "This couldn’t be simpler (at least, most of the time). There are really just two steps. The installation process is a one-time process. It involves downloading code from CRAN (or somewhere else), and unpacking or “building” the code in a location on your machine where your installation of R can find it. It does this all automatically, so you don’t need to make any decisions here.\nOnce it’s installed, you do NOT need to re-install it, unless you want to download a newer version, or unless you change your base installation version of R (like upgrading from 4.5.0 to 4.5.1).\nLet’s do this now for the main graphing package we will use in this course, ggplot2. Run the code chunk below to install this package, if you don’t already have this package installed.\n\ninstall.packages(\"ggplot2\")",
    "crumbs": [
      "Home",
      "Preliminaries",
      "Installing and loading R packages"
    ]
  },
  {
    "objectID": "R_basics_packages.html#how-do-you-use-the-package",
    "href": "R_basics_packages.html#how-do-you-use-the-package",
    "title": "R Basics: installing and loading packages",
    "section": "",
    "text": "If you imagine that your installation of R is like your personal workshop for doing data analysis, installing a new package is like going to the hardware store, buying a cool new tool kit, and then coming home and “installing” it into a special drawer in your workbench. Once it’s installed, you don’t need to go back to the store, unless you want a newer version, or unless you are building a new workshop (i.e., working in a new installation of base R).\nBut you do need to get those shiny new tools out of their special drawer when you want to use them. In R, this means you need to load the package during the session you are using it. You only need to load it once, until you start a new session. In other words, “loading” a package is like taking the tool kit out of its drawer so that you can work with those tools. When the session is done, the tools go back into their drawer, so they will need to be loaded again when you start a new session.\nWe do this using the library() function. So after you have installed the ggplot2 package, you can run the following:\n\nlibrary(ggplot2)\n\nIf you get an error message, then this more than likely means the package was not correctly installed.\nSo just to be clear: you only need to run install.packages(\"packagename\") once, in order to download and install a given package, but then you need to load that package with library(packagename) once every session when you want to use something from that package.1\n1 Note also that you use quotes around the package name when installing, but not when you use library()",
    "crumbs": [
      "Home",
      "Preliminaries",
      "Installing and loading R packages"
    ]
  },
  {
    "objectID": "R_basics_packages.html#what-can-go-wrong-during-installation-how-can-you-tell-and-what-can-you-do-about-it",
    "href": "R_basics_packages.html#what-can-go-wrong-during-installation-how-can-you-tell-and-what-can-you-do-about-it",
    "title": "R Basics: installing and loading packages",
    "section": "",
    "text": "When you run install.packages(), it will not only install the package you asked for, but all of the packages that are dependencies of the package you are installing (plus all of the dependencies’ dependencies, and so on). This is great, because it means R’s package system is doing all the work for you to make sure you have everything you need in order to use the package. This is pretty common, and a sign of a healthy programming community, because it shows how package authors frequently build on the work of others.\nHowever, sometimes it means that you are installing a lot of packages at once, and sometimes things can go wrong during the installation process.\nIn general, a lot of stuff gets printed to the console when a package is being installed, but at the very end, if you see a message that an installation “exited with non-zero status”, it means something didn’t quite work right.\nIn order to figure out what to do, you may need to scroll back through all the console print-outs, and see if there are any warnings or error messages.\nThe most common thing that can go wrong is that a package may depend on some other piece of software that isn’t directly managed by R’s package system. For example, if you are on a Windows machine, you will likely need to install the Rtools software at some point. This is additional software that provides some utilities that are common on macOS and Linux systems, but which are not typically part of a normal Windows installation.\nIn this case, Rtools can be found if you go to the r-project site where you downloaded R the first time, and on the page where you can choose to download “base” R, you should see a link a little lower down to download an installer for Rtools.\nIn other cases, depending on the packages you’re installing, you might need some other utilities or programs. But the pattern is the same: if you “exit the installation with a non-zero status”, you should look through the messages to see if it tells you what you’re missing.\nIf you think you’ve addressed the issue, just try re-running install.packages(), to see if you can get through it without any problems. Once you finally get through the process cleanly, you should be all set.\nIf you run into problems with installation of any packages in this course, please ask for help!\nFortunately, package installation in R is usually pretty headache free, and besides the common need for Rtools on Windows, installation problems are usually pretty rare.",
    "crumbs": [
      "Home",
      "Preliminaries",
      "Installing and loading R packages"
    ]
  },
  {
    "objectID": "R_basics_packages.html#rstudio-installation-messages",
    "href": "R_basics_packages.html#rstudio-installation-messages",
    "title": "R Basics: installing and loading packages",
    "section": "",
    "text": "Recent installations of RStudio also try to assist you with the installation process. For example, if you open up a script or notebook, and RStudio notices that it uses packages that you don’t have installed, it will actually display a small pop-up notice at the top of the window to let you know, and if it knows where to find the package (say, on CRAN), it will even give you a link you can click which will run install.packages() for you.\nIn general, I have had a good experience with RStudio making these suggestions. In other words, if RStudio is making a suggestion, it’s typically a good idea to follow it, and just install what it recommends. I have never had “bloatware” kinds of issues by following RStudio’s prompts.\nOf course, as always, you should be aware of what you’re installing, just in case.",
    "crumbs": [
      "Home",
      "Preliminaries",
      "Installing and loading R packages"
    ]
  },
  {
    "objectID": "R_basics_packages.html#put-all-library-statements-at-the-top-of-your-script",
    "href": "R_basics_packages.html#put-all-library-statements-at-the-top-of-your-script",
    "title": "R Basics: installing and loading packages",
    "section": "Put all library statements at the top of your script",
    "text": "Put all library statements at the top of your script\nSince you only need to load a package once per session, it’s a good habit to put all of your library() statements at the very beginning of the file, so you can load all of your packages in one place, and then you’re good to go.\nThis also has the benefit of making it clear to people who look at your code what packages they will need in order to run your code. That’s a lot more friendly than making someone get halfway through your script or notebook before they realize they need to install some other package.",
    "crumbs": [
      "Home",
      "Preliminaries",
      "Installing and loading R packages"
    ]
  },
  {
    "objectID": "R_basics_packages.html#loading-order-and-masking",
    "href": "R_basics_packages.html#loading-order-and-masking",
    "title": "R Basics: installing and loading packages",
    "section": "Loading order and “masking”",
    "text": "Loading order and “masking”\nOne of the challenges of a system like R that has so many packages is that with so many different authors contributing packages, at some point there may be two different packages that provide a function that happens to be called the same thing.\nFortunately, R has a very reasonable system for handling so-called “namespace clashes.” First, whenever you load a package, R will warn you with statements like:\n\nThe following object(s) is/(are) masked from package ‘package:XXXX’\n\nFor example, one popular package with a lot of useful miscellaneous functions is the MASS package (which stands for Modern Applied Statistics with S. Another popular package is the dplyr package for manipulating data by statistician Hadley Wickham. Both of these packages have a function called select. So if you run library(dplyr) and then library(MASS), you will get a message saying that the object select is masked from 'package:dplyr'.\nIf an object is “masked”, then it is simply not the “default” object of that name. So if MASS and dplyr both have a select() function, but the one from dplyr is masked, then if you just say select(something), you will be using the select function from MASS.\nFortunately, there are a few ways to manage these masking conflicts.",
    "crumbs": [
      "Home",
      "Preliminaries",
      "Installing and loading R packages"
    ]
  },
  {
    "objectID": "R_basics_packages.html#strategy-1-worry-about-the-order-of-library-statements",
    "href": "R_basics_packages.html#strategy-1-worry-about-the-order-of-library-statements",
    "title": "R Basics: installing and loading packages",
    "section": "Strategy 1: worry about the order of library statements",
    "text": "Strategy 1: worry about the order of library statements\nOne way to manage this is just to make sure you library things in the right order, so that the most “important” packages go last, because packages loaded later will mask the previous ones. In the example of select() above, I personally rarely use the select() function from MASS, and I very frequently use the select() function from dplyr, so I basically try to make sure I library MASS first, then dplyr, so that the MASS version will be masked.\nIf you accidentally do them out of order, there is not a good way to “unlibrary” a package during a session. You may just need to re-start your R session in order to start from scratch.",
    "crumbs": [
      "Home",
      "Preliminaries",
      "Installing and loading R packages"
    ]
  },
  {
    "objectID": "R_basics_packages.html#strategy-2-use-the-package-specific-syntax-for-the-masked-function",
    "href": "R_basics_packages.html#strategy-2-use-the-package-specific-syntax-for-the-masked-function",
    "title": "R Basics: installing and loading packages",
    "section": "Strategy 2: use the “package specific” syntax for the masked function",
    "text": "Strategy 2: use the “package specific” syntax for the masked function\nThe best way to make sure that you are using a specific function from a specific package is to use R’s special syntax for this purpose. This looks like:\n\npackagename::functionname()\n\nSo in the example above, if I wanted to make sure I was using the select() function from the dplyr package, instead of the normal:\n\nselect(df, cols)\n\nI could use the special syntax:\n\ndplyr::select(df, cols)\n\nThis will ensure, no matter what is masking what, that I am using the function I am intending to use.",
    "crumbs": [
      "Home",
      "Preliminaries",
      "Installing and loading R packages"
    ]
  },
  {
    "objectID": "installing_R_RStudio_Positron.html",
    "href": "installing_R_RStudio_Positron.html",
    "title": "Installing R and RStudio/Positron for INST 462",
    "section": "",
    "text": "This document is meant to be an aid for installing the main tools we will use in this course: R and RStudio. I’ll give you some brief descriptions of these tools and point you towards the resources you’ll need to install them. Details about how to use them will be covered throughout the course.",
    "crumbs": [
      "Home",
      "Preliminaries",
      "Installing R and RStudio/Positron"
    ]
  },
  {
    "objectID": "installing_R_RStudio_Positron.html#huh-what-do-you-mean-why-do-i-need-both-r-and-rstudiopositron",
    "href": "installing_R_RStudio_Positron.html#huh-what-do-you-mean-why-do-i-need-both-r-and-rstudiopositron",
    "title": "Installing R and RStudio/Positron for INST 462",
    "section": "Huh? What do you mean? Why do I need both R and RStudio/Positron?",
    "text": "Huh? What do you mean? Why do I need both R and RStudio/Positron?\nSo to be a little more specific:\n\nR is a programming language, which means we write code in the “R language” to do our statistical analysis, make graphics, etc.\nR is a type of language called an interpreted language, which means that you can write R code (the language) with any kind of text editor,1 but you need a program called an interpreter that will actually execute the code.\nSo when we say “install R”, what we really mean is “install an R interpreter, so that we can run R code on our machine.” This is what we will go over in this document.\nR is free and open-source,2 and while there are a few different interpreters out there, the most common is one distributed by the R Foundation, sometimes known as “GNU R”.\nGNU R comes with a very bare-bones GUI (graphical user interface) to be able to write and run R, but it’s not the most convenient way to interact with R.\nRStudio and Positron are a products from a company called Posit.3 RStudio is essentially a specialized text editor for writing R code, and it has many useful features.\nPositron has a completely different foundation (as a fork of Visual Studio Code), but aims to provide the same or better functionality as RStudio. But it’s still pretty new.\nBecause Posit is a commercial company, there are paid (“Pro”) and “Server” versions of RStudio, but these are mainly useful if you want to use R in a corporate context.\nThe free (no cost) version of RStudio is perfectly great for individual users, and that’s what we will use in this course.\nWhen you install RStudio/Positron, it will essentially “find” the version of R you have installed, and will make use of that whenever you ask it to run code. But RStudio/Positron are just interfaces to R; they do not include R.\nSo in the end, you need to install R in order to be able to run R code, and you should install RStudio or Positron in order to make it easier to write R code.\n\n1 Note that there are many other good text editors out there. I personally use an editor called Emacs, because I have put in the time to be able to use Emacs for (almost) everything I do. But editors like Emacs or Vim (both of which have been around a loooong time but are still up-to-date) can have a steep learning curve. RStudio and Positron hit a sweet spot of being pretty easy to learn how to use, but very useful when writing R code.\nBut also note that programs like Microsoft Word or Apple’s Pages are NOT text editors, they are word processors, which deal a lot with the formatting and layout of text. A good text editor just focuses on the simple text itself.2 R was founded on open-source principles, and it has been released under the GNU license since 1997. In a nutshell, this means that not only is it free to use and distribute R, but you can inspect every line of code of R (if you so desire), and you can make any kinds of modifications you like to the R installation on your machine.\nThis open-source quality is one of the main reasons R has been so successful. Since it can be easily used and extended by anyone, including bleeding-edge academic statisticians, it is extremely hard for a single commercial product to keep up with all of the features and capabilities that are developed by the R community. The openness also creates an environment of trust, because you can inspect (and alter, if needed) every algorithm or routine in R, so you don’t have to just blindly trust a commercial company.3 RStudio used to be the name of the company, too, and only relatively recently changed their name to Posit, though it’s mainly the same people. While it’s a commercial company, RStudio is headed up by some of the most prolific and influential contributors to R (such as Hadley Wickham), and especially since the RStudio product is still free and excellent, the company is widely respected and highly regarded in the R community.",
    "crumbs": [
      "Home",
      "Preliminaries",
      "Installing R and RStudio/Positron"
    ]
  },
  {
    "objectID": "installing_R_RStudio_Positron.html#pick-a-mirror",
    "href": "installing_R_RStudio_Positron.html#pick-a-mirror",
    "title": "Installing R and RStudio/Positron for INST 462",
    "section": "Pick a mirror",
    "text": "Pick a mirror\nSince R is open-source and the R Foundation is non-profit, there is a longstanding history of R being distributed from multiple sites across the globe. These are called mirrors, because they all host basically the exact same set of web page and download content, just in different sites, to make it easier to manage the load of people accessing and downloading R.\nThe network of mirrors is called the Comprehensive R Archive Network (CRAN). CRAN hosts not only the source code for the “core” installation of R, but also the code for many, many packages (over 20,000 at the time of writing). However, there are also many useful packages and code available in other places, like GitHub or personal websites. CRAN is simply the most common or “centralized” place to get R code.\nSo to download and install R, you just need to go to the following URL, which may ask you to pick a mirror. In general, it’s a good idea to just pick something that’s relatively close to you geographically:\nhttps://cran.r-project.org/",
    "crumbs": [
      "Home",
      "Preliminaries",
      "Installing R and RStudio/Positron"
    ]
  },
  {
    "objectID": "installing_R_RStudio_Positron.html#download-for-your-os",
    "href": "installing_R_RStudio_Positron.html#download-for-your-os",
    "title": "Installing R and RStudio/Positron for INST 462",
    "section": "Download for your OS",
    "text": "Download for your OS\nR also runs on Windows, macOS, and (many flavors of) Linux. Once you pick a mirror you should see links to “Download and Install R” for your operating system. So just click the link and follow the instructions! You just may want to double-check your operating system to remind yourself what you have, and make sure to download the installer or set of files that is appropriate for your version.\nIf you are in doubt about 32- or 64-bit, it’s safe to assume 64-bit, unless your machine is really old.\nFeel free to contact the instructor (or UMD IT) if you need any assistance with installation.",
    "crumbs": [
      "Home",
      "Preliminaries",
      "Installing R and RStudio/Positron"
    ]
  },
  {
    "objectID": "installing_R_RStudio_Positron.html#run-the-installer",
    "href": "installing_R_RStudio_Positron.html#run-the-installer",
    "title": "Installing R and RStudio/Positron for INST 462",
    "section": "Run the installer",
    "text": "Run the installer\nGenerally, when you run the installer after downloading it, you should just pick the default installation options as you go. If you have any questions about the different options, again please feel free to reach out to your instructor.",
    "crumbs": [
      "Home",
      "Preliminaries",
      "Installing R and RStudio/Positron"
    ]
  },
  {
    "objectID": "installing_R_RStudio_Positron.html#verify-your-installation",
    "href": "installing_R_RStudio_Positron.html#verify-your-installation",
    "title": "Installing R and RStudio/Positron for INST 462",
    "section": "Verify your installation",
    "text": "Verify your installation\nOnce you have R installed, you can run R code! If you try to start R, what your interface looks like will depend somewhat on what your operating system is. But most likely you will see a window open somewhere that displays the following text (or something close to it; your platform may differ):\nR version 4.5.1 (2025-06-13) -- \"Great Square Root\"\nCopyright (C) 2025 The R Foundation for Statistical Computing\nPlatform: x86_64-pc-linux-gnu\n\nR is free software and comes with ABSOLUTELY NO WARRANTY.\nYou are welcome to redistribute it under certain conditions.\nType 'license()' or 'licence()' for distribution details.\n\n  Natural language support but running in an English locale\n\nR is a collaborative project with many contributors.\nType 'contributors()' for more information and\n'citation()' on how to cite R or R packages in publications.\n\nType 'demo()' for some demos, 'help()' for on-line help, or\n'help.start()' for an HTML browser interface to help.\nType 'q()' to quit R.\nThis is the standard “welcome” text for the most current version of R, version 4.5.1 (from June 13, 2025). If you see this somewhere when you try to run R, then your installation worked! You can just close this console for now.",
    "crumbs": [
      "Home",
      "Preliminaries",
      "Installing R and RStudio/Positron"
    ]
  },
  {
    "objectID": "installing_R_RStudio_Positron.html#download-and-run-installer",
    "href": "installing_R_RStudio_Positron.html#download-and-run-installer",
    "title": "Installing R and RStudio/Positron for INST 462",
    "section": "Download and run installer",
    "text": "Download and run installer\nRStudio is also easy to install, and since it’s only distributed by Posit (it has many open-source components, but it’s not 100% open-source), you just go here to get it:\nhttps://posit.co/download/rstudio-desktop/\nNote that on this page, “Step 1” says to install R, and they have a link to CRAN, but we already did this step above, so you don’t need to do it again. It’s just a reminder that it’s a good idea to install R first, before you install RStudio, so that when you install RStudio, it can more easily find the version of R you have on your machine.\nAgain, RStudio is available for Windows, macOS, and several versions of Linux, so pick the installer that matches your system, follow the directions, and ask your instructor for help if you run into any problems.\nI recommend using the “installer” download (.exe, .dmg, .deb) instead of the “zip/tarball” option. And again, I recommend the default options when going through the installation process.",
    "crumbs": [
      "Home",
      "Preliminaries",
      "Installing R and RStudio/Positron"
    ]
  },
  {
    "objectID": "installing_R_RStudio_Positron.html#verify-installation",
    "href": "installing_R_RStudio_Positron.html#verify-installation",
    "title": "Installing R and RStudio/Positron for INST 462",
    "section": "Verify installation",
    "text": "Verify installation\nAfter you have RStudio installed, try starting it up on your machine. The interface has a few different panels (or “Panes”), but by default, the first time you start it, you should see the same welcome text given above on the left pane. In other words, if you start RStudio and it gives you the welcome text that starts with something like:\nR version 4.5.1 (2025-06-13) -- \"Great Square Root\"\nCopyright (C) 2025 The R Foundation for Statistical Computing\nThen you’re good to go!",
    "crumbs": [
      "Home",
      "Preliminaries",
      "Installing R and RStudio/Positron"
    ]
  },
  {
    "objectID": "installing_R_RStudio_Positron.html#download-and-run-installer-1",
    "href": "installing_R_RStudio_Positron.html#download-and-run-installer-1",
    "title": "Installing R and RStudio/Positron for INST 462",
    "section": "Download and run installer",
    "text": "Download and run installer\nDownload links for Positron can be found here:\nhttps://positron.posit.co/download.html\nNote that you need to check the box indicating that you agree to the license agreement before the download links become active.\nSimilar to RStudio, you just need to make sure you select a link that is appropriate to your system.",
    "crumbs": [
      "Home",
      "Preliminaries",
      "Installing R and RStudio/Positron"
    ]
  },
  {
    "objectID": "installing_R_RStudio_Positron.html#verify-installation-1",
    "href": "installing_R_RStudio_Positron.html#verify-installation-1",
    "title": "Installing R and RStudio/Positron for INST 462",
    "section": "Verify installation",
    "text": "Verify installation\nPositron is designed to have a similar layout to RStudio, at least by default, but it also has a different set of UI elements, so it’s a little different.\nMost of the time, if you are just starting Positron for the first time, and you already have R installed on your machine, it will auto-detect the most recent version of R, much like RStudio does, and the interface will also display an R console with the standard welcome text.\nIf instead the interface console says that you need to “Start Session”, you can click the “Start Session” button in the upper right of the interface to select a version of R. Note that you can also use this same button to select a version of R or Python on your machine, depending on what you want to run in the console window.\nBut as long as you can open Positron and then start an R console running with your most recent version of R, you’re all set.",
    "crumbs": [
      "Home",
      "Preliminaries",
      "Installing R and RStudio/Positron"
    ]
  },
  {
    "objectID": "installing_R_RStudio_Positron.html#should-you",
    "href": "installing_R_RStudio_Positron.html#should-you",
    "title": "Installing R and RStudio/Positron for INST 462",
    "section": "Should you?",
    "text": "Should you?\nAt some point, you may want to install a new version of R. R tends to update roughly every 6 months. Or you may have R already from a previous class or other experience. Should you upgrade?\nIn a nutshell, yes, you should almost always just go ahead and upgrade, unless you have a very specific reason that you need a specific version on your machine. The releases are extremely stable, and always include various improvements and changes, and since they only update R every six months or so, it’s not that onerous to just go ahead and do it.\nBecause R is very stable, it’s also quite backwards-compatible, so it’s rare that having an older version is much of a problem. However, whenever you want to install a new package, if your base version of R is behind, it may warn/complain that the package was built under a different version than your current version. This is another reason why it’s typically less of a headache to just go ahead and update your version of R when a new one comes out, because then you don’t need to worry about it being out of sync with your packages.",
    "crumbs": [
      "Home",
      "Preliminaries",
      "Installing R and RStudio/Positron"
    ]
  },
  {
    "objectID": "installing_R_RStudio_Positron.html#how-to-install-a-new-version-and-what-to-do-about-older-versions",
    "href": "installing_R_RStudio_Positron.html#how-to-install-a-new-version-and-what-to-do-about-older-versions",
    "title": "Installing R and RStudio/Positron for INST 462",
    "section": "How to install a new version (and what to do about older versions)",
    "text": "How to install a new version (and what to do about older versions)\nIf you do want to install a new version of R over an existing version, you simply follow the same steps as if you were installing it for the first time.\nOne quirk is that depending on your operating system, this may result in you having multiple versions of R installed on your machine at the same time. This is typically the case with Windows, but not as common with macOS or Linux. This is not necessarily a problem, and the R installation is not gigantic, so unless you are pressed for hard drive space, you may not need to even worry about it. But if you don’t want older versions, you can uninstall those just fine without it interfering with your newer installation.\nAdditionally, all decent R editors (including RStudio) have ways to detect different installations, so you should see that they use the latest version you have installed (though you may need to restart RStudio before it switches).",
    "crumbs": [
      "Home",
      "Preliminaries",
      "Installing R and RStudio/Positron"
    ]
  },
  {
    "objectID": "installing_R_RStudio_Positron.html#packages-for-an-updated-installation",
    "href": "installing_R_RStudio_Positron.html#packages-for-an-updated-installation",
    "title": "Installing R and RStudio/Positron for INST 462",
    "section": "Packages for an updated installation",
    "text": "Packages for an updated installation\nWhile installing a new version over an older version is usually not a problem, it does mean that you will need to re-install packages. We will discuss package installation in a different tutorial, but I’m just pointing it out here, that packages don’t “carry over” when you install an updated version of the base R installation.",
    "crumbs": [
      "Home",
      "Preliminaries",
      "Installing R and RStudio/Positron"
    ]
  },
  {
    "objectID": "R_basics_fundamentals.html",
    "href": "R_basics_fundamentals.html",
    "title": "R Basics: fundamentals of working with R",
    "section": "",
    "text": "If you have never used R before, this is for you. This tutorial will walk you through some of the basics you need to know about how R works and how you can work with R, before we get to other topics.\nEven if you have used R before, I encourage you to go through this content as a refresher. It may even have some new things, or it might help clarify things you’ve done in the past.\nIf you want the full R Markdown document that this page is based on, you can download it from the course site on ELMS. Otherwise, feel free to copy & paste code from here into your own .R script or R Markdown document. Either way, you should run the code seen here, modify it, and generally play around with it to make sure you are understanding how it works.",
    "crumbs": [
      "Home",
      "Working with data in R",
      "Getting started with R"
    ]
  },
  {
    "objectID": "R_basics_fundamentals.html#some-history",
    "href": "R_basics_fundamentals.html#some-history",
    "title": "R Basics: fundamentals of working with R",
    "section": "Some history",
    "text": "Some history\nWorking at the console can be very convenient, but once we start doing anything more meaningful, we would like to be able to save our commands, instead of re-typing things every time.\nThe basic way to do this is to save code in a file with a .R extension. This type of file is often called a “script.” A file with the .R extension is treated as if everything in that file is R code.\nScripts are very useful, and when you just want to write code, they are usually the way to go. You can also add “comments” in your code, which is just a way to tell the R interpreter to ignore parts of a line when executing the code. For example, you could have something like the following in a .R script:\n\n# this is a comment, and is ignored\n# the `#` symbol tells R to ignore EVERYTHING TO THE RIGHT\n# the following code will be NOT be executed, because\n# it has a `#` in front of it:\n# 42 * 83\n\n# but the next line WILL be executed:\n42 * 83\n\n[1] 3486\n\nprint(\"hello\") # you can also put comments after code on the same line\n\n[1] \"hello\"\n\n\nIf you are writing your code in a .R file, since everything is treated as R code, you have to use comments if you want to write or explain anything using anything other than valid R code. However, when we do data analysis, we often want to mix our code with more descriptive (aka wordy) narrative about what we are doing, how we are interpreting results, and so on, and comments are just not a good way to include a lot of more detailed documentation or narrative.\nIn fact, R has a long history of being one of the first and best languages to implement a paradigm called “literate programming.”1 The concept of literate programming is that it is a mix of code and text, and that some system is in place for treating the two differently. The pioneering method for doing this in R was called “Sweave”,2 and it was a mix of R code and LaTeX. LaTeX is another language that acts as a kind of mark-up language for formatting text, and it is still popular in some fields like mathematics.\n1 This concept was coined and championed by the legendary computer scientist Donald Knuth. There are lots of places to read more about the original ideas, including this ancient-looking page.2 More trivia: the R language is an open-source project based on a commercial language called S that was developed at Bell Labs in the 1970s. The name S was a bit of a “programming pun” on the name of the C language, with S for “statistics.” In turn the name of the R language was a pun on S, because R was originally developed by two statisticians whose names both started with “R”: Ross Ihaka and Robert Gentleman. To bring us full circle, the term “Sweave” refers to the literate programming concept of “weaving” S code with text, so it’s pronounced “S-weave”.Sweave still works great if that’s what you want, but learning LaTeX in addition to R makes the entire learning curve steeper, so people were interested in coming up with a better alternative. Enter R Markdown.\nMarkdown itself is a simple mark-up language that was originally invented to provide some simple ways to write text that could be converted to HTML. The original Markdown was created by John Gruber on his blog “Daring Fireball”, and you can still find info about it there:\nhttps://daringfireball.net/projects/markdown/syntax\nBut because Markdown made it really easy to write documents in a way that they could be easily converted to HTML, it became really popular, and now you can find Markdown everywhere, being used for all sorts of things. Here’s one reference site you might find useful if you want to learn more about it:\nhttps://www.markdownguide.org/\nBut the point for us is that some people decided that R + Markdown would be an easier thing to work with than R + LaTeX, and that’s where the idea of “R Markdown” came from. R Markdown files have the extension .Rmd (Markdown by itself is just .md) or .qmd for Quarto files, and they are a mix of R code and Markdown-formatted text.\nOver time, people implemented more and more features, and the rmarkdown package now enables a lot of different ways to use R Markdown. In fact, there is a lot of overlap between the people who created and maintain RStudio and the people who created and maintain the rmarkdown package, so R Markdown is especially feature-rich when you use RStudio.\nIn fact, this specific document is written in a new type of R Markdown document called Quarto, which can be used to easily generate good looking web documents like blogs, research papers, and so on. If you’re interested in this kind of thing, I can highly recommend Quarto as a kind of “next evolution” in R Markdown documents. In this course, you will have access to the .qmd files of these tutorials, but I will post regular .Rmd files for assignments and practice exercises. The differences between these are not huge, since they both use a mix of Markdown text with R code chunks. But .Rmd files are typically a little simpler to use for one-off assignment, reports, notebooks, etc., while Quarto files are often intended to link together in a system like a website.\nFinally, R Markdown and its related formats share some things with the Jupyter system, which is popular with many Python users, particularly in data science.3 However, one of the nice things about R Markdown is that it does not require the more complex kernel/server architecture of Jupyter, and it can more easily be converted into a variety of other formats beyond HTML, including PDF (which is actually rendered via LaTeX, to go full circle) and even Microsoft Word formats.\n3 Just for reference, the Jupyter system was originally envisioned as supporting R, Python, and Julia languages, which is where the name comes from: JU-lia, PY-thon, and R. In practice, it has become an extremely popular way to write “notebook”-style documents in Python, but it hasn’t caught on as much with the other languages. I personally find Jupyter a little more onerous to work with, though it can work very well in a hosted server type of environment. But note that Positron works well with Jupyter notebooks, while RStudio does not.",
    "crumbs": [
      "Home",
      "Working with data in R",
      "Getting started with R"
    ]
  },
  {
    "objectID": "R_basics_fundamentals.html#using-r-markdown-in-this-course",
    "href": "R_basics_fundamentals.html#using-r-markdown-in-this-course",
    "title": "R Basics: fundamentals of working with R",
    "section": "Using R Markdown in this course",
    "text": "Using R Markdown in this course\nOkay, that’s the long background that explains some of the differences and reasons behind these types of files, but how do you use R Markdown?\nThe fundamental idea is that when you type in an R Markdown document, it’s just simple text in the Markdown format. This works great for typical kinds of documentation, like writing paragraphs of text, using headings to create a document structure, using lists (numbered and bulleted), simple tables, and so on. You use special characters to create formatting, as described by all those guides on Markdown that I referred you to earlier. So for example, # symbols at the beginning of a line are not “comment” characters, but rather they create a “heading”, where the number of # symbols designated the “level” of the heading (# is top-level heading, ## is level 2, ### is level 3, etc.). I recommend just spending a few minutes browsing one of the Markdown overviews linked above to get a feel for the most common options.\nThe point here is that Markdown is a nice, simple format for writing text. But when you want to write R code, you need to designate a “code chunk”, using the following symbols (these are only visible in the raw .qmd file):\nThe symbol that starts and ends chunks is called a “backtick” symbol, or sometimes a “grave accent”, and it’s the character you get from the key just to the left of the “1” key (at least on a standard English-language keyboard). Three of those backtick symbols starts the code chunk, and another three end it. Finally, on the first line, just after the opening three backticks, you use curly braces with the name of the language, in this case you use a lower-case r. Inside those curly braces, you can also put options that change how the chunk behaves, but we’ll get to those another time.\nSo you want to run R code inside an R Markdown file or R Notebook, you just make a code chunk and write your code on the lines between the backticks. All of the text inside the code chunk is treated as R code, and it runs just as if you were working with that code inside a plan .R file. For example, the following chunk will perform a calculation.\n\n(4 + 10) * 3\n\n[1] 42\n\n\nIn RStudio, there are a few different ways to run the code in a chunk. If you want to run ALL the code in a chunk, there is a little green “play” arrow in the upper right of the chunk itself. This will run every line of code in the chunk, one line after another, immediately and without stopping. There is also a button to run every chunk above (but not including) the current chunk, which can be helpful as well.\nIn Positron, there are similar “buttons”, but they look a little different, labeled as text (“Run Cell”, “Run Next Cell”, and “Run Above”) instead of icons. “Run Cell” does what it says, “Run Next Cell” skips your cursor down to the next code chunk, wherever that is, and runs that chunk, which makes it a little easier to step through the code in your document chunk by chunk. And the “Run Above” button does the same as the “”\nIf you just want to run one line at a time (which I personally find very useful), just put your cursor on the line you want to run (anywhere is fine), hold the Ctrl key (on Windows) or Command key (on Mac), and hit Enter. The cursor will also skip down to the next line, so you can just hold Ctrl/Command and hit Enter repeatedly to run multiple lines. Being able to run one line at a time is often very useful in R, since the process of data analysis and visualization is often highly interactive and incremental.\nSo overall, the advantage of this kind of file (in conjunction with a good editor like Positron or RStudio) is being able to have both R code as well as other lightly-formatted text in the same document, which you can export to multiple formats as output.",
    "crumbs": [
      "Home",
      "Working with data in R",
      "Getting started with R"
    ]
  },
  {
    "objectID": "R_basics_fundamentals.html#functions-do-things",
    "href": "R_basics_fundamentals.html#functions-do-things",
    "title": "R Basics: fundamentals of working with R",
    "section": "Functions do things",
    "text": "Functions do things\nWhile we may use structures like vectors or data frames (covered in other tutorials) to act as containers for data, most of the time we want to actually do stuff with data, and that’s what functions are for. To put it another way, functions are the “verbs” of the R language.\nI won’t discuss how to create your own functions yet (it’s actually very easy), but for now I’ll just focus on how to use functions.\nThe syntax for running a function is always the same:\n\nfunction_name(argument1, argument2, …)\n\nEvery function has a name, which is essentially the same kind of thing as a variable name. It just refers back to an object that’s made up of code, instead of an object that contains other kinds of data values.\nFollowing the name, you must use parentheses. That’s what tells R, “I want to run this function.” This is why you’ll sometimes see functions with just a pair of parentheses with nothing between them, because even if you don’t need to pass it any arguments, you still need the parentheses.\nOn example of this is the objects() function, which prints out a list of all the objects in your “workspace”, which is basically the objects that are currently in memory that you can access. Run the following, and you should see my_result listed (at least, if you ran the code above assigning a value to my_result), plus any other variables/objects you have created in this session of R.\n\nobjects()\n\n[1] \"my_result\"\n\n\nThe objects function doesn’t need an argument, because by default it shows you the contents of your “Global Environment” workspace. But if you want to run the function, you still need the parentheses.\nIf you just entered objects without the parentheses, R would actually print out the code that is represented in the objects function.",
    "crumbs": [
      "Home",
      "Working with data in R",
      "Getting started with R"
    ]
  },
  {
    "objectID": "R_basics_fundamentals.html#using-arguments-in-functions",
    "href": "R_basics_fundamentals.html#using-arguments-in-functions",
    "title": "R Basics: fundamentals of working with R",
    "section": "Using arguments in functions",
    "text": "Using arguments in functions\nSo while some functions can just run like this with nothing in the parentheses, most of the time, you will use arguments. Arguments are the values that go inside the parentheses of the function, and they are separated by commas. You can think about arguments as the “input” values of the function. In other words, it’s what the function needs to know in order to do its job.\nFor example, the function rnorm will generate random samples from a normal distribution (we will get to what all that means soon!), and the only argument it really needs is a number to tell it how many samples to generate. Try running the following:\n\nrnorm(10)\n\n [1]  0.87346987 -0.72982888 -0.01305619 -0.19888273 -0.66369360 -0.65602221\n [7]  0.05264088 -0.50162086  0.89801198 -1.76602701\n\n\nEvery time you run it, you’ll get different numbers. Now try deleting the 10 and see what happens (see below). It will give you an error and tell you that an argument is missing.\n\nrnorm()\n\nMost functions actually have several arguments. So if you enter in several values separated by commas, how does R know which value goes with which argument? It turns out that R has a few different ways of doing this, which makes specifying arguments pretty convenient.\nFirst off, arguments have names, and if you specify their names using the = (“single equal-sign”) operator, you can enter them in any order. For example, in that rnorm() error message above, it tells you that argument \"n\" is missing. So we could specify the code as:\n\nrnorm(n = 10)\n\n [1] -0.6417071  1.3256464 -1.8218717  0.4755740  1.1210029 -1.0083532\n [7] -0.3349143  3.1073944 -0.6750325 -1.0784051\n\n\nThe syntax here is that you put the name of the argument first, followed by a = symbol, followed by a value, and spaces are optional. Note that when we are assigning values to arguments, we use the = sign, not the “assignment arrow” &lt;- symbol. In this example, we are just being very explicit about which argument we want that 10 to go to.\nA second way that R knows which arguments are which is by the order they come in. For example, the rnorm() function has three arguments: n, mean, and sd, in that order. So if we give three values without names, then R assumes we are providing the arguments in order. So the following two lines of code are identical. The first uses explicit argument names, and the second just provides the arguments in order.\n\nrnorm(n = 5, mean = 100, sd = 10)\n\n[1]  97.16769  88.96454 108.47908 110.51393 103.50652\n\nrnorm(5, 100, 10)\n\n[1]  97.25989 106.96917  90.44560  96.44620  82.20708",
    "crumbs": [
      "Home",
      "Working with data in R",
      "Getting started with R"
    ]
  },
  {
    "objectID": "R_basics_fundamentals.html#default-values-for-arguments",
    "href": "R_basics_fundamentals.html#default-values-for-arguments",
    "title": "R Basics: fundamentals of working with R",
    "section": "Default values for arguments",
    "text": "Default values for arguments\nIf you were paying careful attention, you might have noticed that in the code above we used three arguments, but the first time we ran rnorm(), we only gave it a single argument. Why was that good enough?\nMany functions in R have default values for some (or even all!) of their arguments. This is helpful because with many functions, there are some “standard” values that make sense, and if you don’t have to enter those in every time, it’s convenient.\nFor example, in our rnorm() function, the mean and sd arguments default to 0 and 1, respectively. This means that if we only give rnorm() a value for its n argument (representing the number of samples we want), then it will give us samples with a mean of 0 and a standard deviation of 1. These are good choices for defaults, because they represent the values that correspond to what’s called the standard normal distribution.\nSo in essence, the default argument values in R are chosen by whoever wrote the definition of that function. Since R is a language for statistical analysis, this means most of the default values are chosen based on common practices or whatever the author thought were good “starting place” values.\nThat said, one nice thing about default values is that we can easily change them. Changing values of an argument are sort of like changing the “settings” or “options” that the function uses to produce a result. Try running each of the following and look at how the overall pattern of values changes:\n\nrnorm(10)\n\n [1] -0.3910379  1.1455213  0.7030155  0.9359570  0.7394294  0.5751610\n [7] -0.7955337  1.4641372 -0.4581218  1.2494744\n\nrnorm(10, mean = 30)\n\n [1] 29.75585 31.50328 29.55525 29.26746 30.37592 29.39258 30.59231 30.21079\n [9] 28.37301 27.25139\n\nrnorm(10, sd = 10)\n\n [1]  12.557222 -11.422692  -9.101778  13.249779   4.839099  10.826151\n [7]   1.985022  24.862552  -5.605314   7.369286\n\nrnorm(10, mean = 30, sd = 10)\n\n [1] 64.52177 27.70743 26.96277 35.43046 25.48846 31.05008 15.53828 39.44777\n [9] 19.06622 41.69170\n\n\nYou should see different patterns according to the different arguments, which you can see as changing the “settings” of the function. Recall that the default of mean is 0 and the default of sd is 1.If you don’t notice any differences, edit the values to be larger to make more extreme patterns.\nFinally, it’s important to know that not all arguments have default values. Remember how we got an error when we tried running rnorm() without any arguments? This is because there is no default value for n. This makes sense, because if you want to generate samples, you ought to at least tell R how many samples you want. But again, this is a choice made by the author of the rnorm() function. Different functions may differ on how many arguments have defaults or not.",
    "crumbs": [
      "Home",
      "Working with data in R",
      "Getting started with R"
    ]
  },
  {
    "objectID": "R_basics_fundamentals.html#mixing-order-names-and-defaults",
    "href": "R_basics_fundamentals.html#mixing-order-names-and-defaults",
    "title": "R Basics: fundamentals of working with R",
    "section": "Mixing order, names and defaults",
    "text": "Mixing order, names and defaults\nNow examine the following closely:\n\nrnorm(n = 10, mean = -10, sd = 17)\nrnorm(10, -10, 17)\nrnorm(10, sd = 17, mean = -10)\n\nIt turns out that these three lines are identical.4 They illustrate how flexible R is when it comes to specifying arguments. In the first example, we give all three arguments with their names, in the default order. In the second line, we simply give the arguments in order, and R knows what to do with them. It’s just a little riskier to do this, because we need to be confident that we are putting things in the order that R expects.\n4 You can run these yourself to verify. Just remember that this function is generating random numbers, so the actual values will be different, but you should play around with them enough to convince yourself that these lines do all do the exact same thing.The third line is maybe the most representative of typical practice when you are using R for real analysis. The first argument is given without the name, but it represents the argument that doesn’t have a default, n. It’s important to note that in R, arguments without defaults always come before arguments with defaults. Again, for rnorm(), we just know that we need to tell it how many samples to generate. Then the mean and sd arguments are specified, because we want something different from the defaults. But notice that they are “out of order.” This is okay!\nBasically, if you specify arguments by name, they can come in any order. This is nice because it means you don’t have to worry about both order and name. As long as you have the order right or the names right when specifying arguments, R can essentially figure out what you mean. This is one of those design features of R that really comes in handy for day-to-day use.\nTo sum this up, in practice, what people commonly do is:\n\nspecify required arguments5 in order\n\nmaybe only providing names if you sometimes have trouble remembering the order\n\nprovide names for arguments that normally have default values\n\nnot because you have to, but just because those are the arguments that people are naturally less familiar with, so providing names just helps make the code more clear\n\n\n5 Required arguments are arguments that do not have a default value.At this point, you may be asking yourself:\n\nHow do I know what the arguments are, which ones have defaults, and what are those default values?\n\nThis is where we get to talk about the great internal help system in R.",
    "crumbs": [
      "Home",
      "Working with data in R",
      "Getting started with R"
    ]
  },
  {
    "objectID": "R_basics_fundamentals.html#feedback-from-r-errors-and-warnings",
    "href": "R_basics_fundamentals.html#feedback-from-r-errors-and-warnings",
    "title": "R Basics: fundamentals of working with R",
    "section": "Feedback from R: Errors and Warnings",
    "text": "Feedback from R: Errors and Warnings\nThis is a bit of a miscellaneous topic, but I think understanding it can help new users of R navigate things when they run into problems. Running into problems is normal, and just part of the programming cycle!\nR has two major categories of “problems”: errors and warnings. The way to think about both of these is that they are ways for the programmers of R to communicate with you, the user. In a nutshell:\n\nErrors happen when something goes wrong and the code doesn’t work at all. The message you get is supposed to give you some clues about what may be the problem, but it can take some experience and/or sleuthing before you understanding exactly what an error message may be trying to tell you.\nWarnings happen when the designer of a function is trying to tell you, “well, I technically did what you asked me to do, but just in case, I’m going to give you some additional info in case this isn’t really the result you wanted.”\n\nSo the first distinction to notice is that when an error happens, the code basically doesn’t run. You asked R to do something, and it said “no.” In contrast, when a warning happens, the code did run, and it gave you a result. It’s just giving you a heads-up, in case the result wasn’t actually what you wanted.\nFor example, it’s pretty common to get warnings having to do with missing data. When you get to the topic of coercion in the next tutorial, you’ll learn about what happens when you try to tell R to force data to be a number when R doesn’t know how to make it a number. In short, it does the best it can, but when it doesn’t have a way of doing it, it’ll replace that value with a missing value (NA). But it will also warn you about this, giving you the message: Warning: NAs introduced by coercion. This basically means, “okay, I did what you asked me to, but just FYI, the result now has some missing values that weren’t there before.”\nThe main point here is that as you are learning R and trying to make sense of things, one of the first things to notice about any messages you get back is whether it’s an error or a warning. But don’t ignore warnings just because you can! They can sometimes reveal that something unexpected is happening, and you may be making a mistake that you wouldn’t catch otherwise.\nAs a final point, some package authors are extremely liberal with warnings. The popular set of packages known as the tidyverse has many functions that will warn you about everything, almost to the point of being annoying. So just be aware that ultimately, warnings and error messages are just little notes sent to you by the human who programmed the function(s) you’re using, and those humans can make interesting choices sometimes, and part of learning R is learning about how different authors handle things differently.",
    "crumbs": [
      "Home",
      "Working with data in R",
      "Getting started with R"
    ]
  },
  {
    "objectID": "R_basics_vectors.html",
    "href": "R_basics_vectors.html",
    "title": "R Basics: vectors",
    "section": "",
    "text": "R has a lot of different data structures, but for the purposes of this course, we will try to keep our focus as narrow as possible, which means that we will focus almost exclusively on vectors and data frames. This document walks you through how to use vectors, along with several other tips and functions that frequently come in handy. A separate document will do the same for data frames, but that document assumes you understand vectors, so please go through this tutorial first.\n\n\nOne of the fundamental constructs in data analysis and statistics is the concept of a variable. In the R Fundamentals tutorial, we also discussed a different kind of “variable.” Usually the context will make it clear which one we are talking about, but if we need to be less ambiguous, I will sometimes refer to “data variables” vs. “programming variables.”\nA data variable is a variable in the statistics sense, namely a set of values that corresponds to data on a particular scale, such as a set of years, or length measurements, or dollar amounts, or genders of respondents, or crime rates, or song titles, or flower species, or whatever. A programming variable is the use of a symbol1 that names an object in memory. So when we say something like, “pick a variable from your data set”, we are talking about a “statistics variable,” but when we say something like, “assign this value to a new variable in your code,” we are talking about a “programming variable.”\n1 And by symbol, I mean “set of valid characters.” In R, we can use alphanumeric characters (letters and numbers), plus a couple of other characters like underscores and periods to form a variable name. That variable name is a symbol in this technical sense.Sorry if this feels like weird nitpicking. But there are times when we use similar (or even the same!) words for different concepts in statistics vs. programming, and I just want to call attention to where that happens, in case those terms are creating confusion for you.\nBack to the topic at hand, in R, statistics variables are usually represented by a structure that R calls a vector. In other programming languages, this might be called an array.2\n2 R also has array structures, which are essentially multi-dimensional vectors. This is another aspect of terminology that can be confusing, when programming languages use terms differently. Unfortunately, since we can’t really change how different languages have already named things, the best we can do is try to keep track. For example, R and Python both have things called “lists”, but they have a lot of differences. If you are coming from Python, the closest thing to R’s vector structure is the array from the NumPy library.A vector in R is essentially just a series of values, and by “series”, I mean that there’s an order to them, and the order usually matters. This is typical in data analysis, because the data in a vector might correspond to the order that the data was collected in, or perhaps it is arranged in another way that is meaningful.\nAnother key property of vectors in R, which does match our definition of a statistics variable, is that all of the values in a vector have to match in type. That is, they can all be numbers, or all strings, or all some other type of object, but you can’t mix data types in a vector in R.3\n3 If you want a structure where you can mix types in R, you should use a list. This is something that R lists do have in common with Python lists, if you’re keeping track.These properties make vectors natural ways to represent statistics variables.\nFurthermore, almost any time you generate a simple series or sequence of values (whether those are numeric or some other type), it’s treated as a vector. And because vectors are kind of the “default” data structure in R, R gives you lots of convenient ways to create them.\nFor example, we can use the colon operator : to generate a sequence of integers. The following creates a vector of integers from 1 to 10, inclusive of both. Run this code and modify it until you understand what it’s doing.\n\nshort_vector &lt;- 1:10\nprint(short_vector)\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nThe colon operator is convenient, but there is a function seq() (for “sequence”) that gives us a lot more control over creating a sequenced numeric vector. In this function, you give it a starting value, an ending value, and a value that represents the “step” you take between values. For example, the following creates a sequence from 0 to 1, stepping by 0.1, another sequence from 10 to 30 stepping by 2, and a third sequence from 1 to 100 stepping by 5. To illustrate some of what we discussed in the previous tutorial, I’ll mix up how the arguments are specified, to show you a few different options.\n\nsequence1 &lt;- seq(0, 1, 0.1)\nprint(sequence1)\n\n [1] 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0\n\nsequence2 &lt;- seq(to = 30, by = 2, from = 10)\nprint(sequence2)\n\n [1] 10 12 14 16 18 20 22 24 26 28 30\n\nsequence3 &lt;- seq(1, 100, by = 5)\nprint(sequence3)\n\n [1]  1  6 11 16 21 26 31 36 41 46 51 56 61 66 71 76 81 86 91 96\n\n\nOne more note about the seq() function. In sequence3, we asked it to increment by 5 from 1 to 100. But it only got to 96, because the next value by 5 would be 101, which is beyond the to value. This is just an example that you might want to double-check your sequences if you make them, to confirm that they are giving you the values you want. If we actually wanted a vector that counted by 5’s up to 100, we would want something like seq(0, 100, by = 5) instead.\n\n\n\nWhile ordered sequences are handy, we sometimes want to make vectors out of series of numbers (or other data) that are not necessarily an orderly sequence. For this, R uses a simple function c() (which stands for “concatenate”) that simply converts its arguments into a vector. For example:\n\nsome_numbers &lt;- c(3, 66, 1, 5849, 42, 0.33, pi) # pi is a number in R!\nsome_words &lt;- c(\"person\", \"woman\", \"man\", \"camera\", \"TV\")\n\nBoth some_numbers and some_words are vectors. The point is that just a series of items separated by commas is not automatically interpreted as a vector. If you want to “manually” type in a vector in R, you need to use the c() function to create a vector from its arguments (separated by commas).\n\n\n\nAs I mentioned above, one crucial aspect of vectors in R is that they are homogeneous, meaning that the entire vector has to contain the same type of data. For example, you can have a vector of numbers, like some_numbers above, or a vector of strings, like some_words above, but you can’t have a mixed vector of some numbers and some strings. However, R doesn’t stop you from trying:\n\nmixed_vector &lt;- c(467, 2, \"apple\", 487, \"three\")\nprint(mixed_vector)\n\n[1] \"467\"   \"2\"     \"apple\" \"487\"   \"three\"\n\n\n\n\nIn some programming languages, something like the above produce an error, but R tries to be helpful by giving you a result back. In this example, all of the numeric values have been coerced into strings. This process of coercion is common throughout R. It is often convenient and helpful, but it can also lead to problems when you’re not careful or if you’re unaware it’s happening.\nOne example you may encounter is that when you read in data, you might find that a column of what should be numbers is not treated as numeric, but rather as characters. This might be because R treats columns as vectors (so they must be homogeneous), and then somewhere in the column there might have been a value that was not numeric (like a value with a stray character in it), so the entire vector was coerced into a character vector. For example, if you have a column of dollar amounts as integers but one amount is listed as the string “not available”, that column may be coerced into a character vector.\nIn short, coercion is a process that R frequently uses to avoid errors by converting the data to the “lowest denominator”, meaning the data type that has the least restrictions. So while the number 1 can be coerced to the character “1”, the word “hello” cannot be coerced to a number.\n\n\n\nBut you can also force R to convert a vector into another data type. There are a bunch of functions that all start with as. that do this, like as.numeric(), as.integer(), as.character(), as.factor(), as.data.frame() and so on. When you use these, R does the best it can. For example, see what happens when we try to force our mixed_vector from above to be numeric:\n\nmixed_vector_num &lt;- as.numeric(mixed_vector)\n\nWarning: NAs introduced by coercion\n\nprint(mixed_vector_num)\n\n[1] 467   2  NA 487  NA\n\n\nWhat happens is that for the values where R has a method for converting that value to a number, it does so. This is why we can get the number 467 from the string \"467\". It’s pretty intuitive to think about taking a string of numeric characters and converting into numeric type data, so this is nice. But R essentially doesn’t know how to convert a character string like “apple” or “three” to numbers, so it substitutes a special NA value if you force those values to be numeric type data. Fortunately, R also gives you a warning message when this happens, just in case you weren’t expect it. This special NA value is important enough to warrant a short excursion.\n\n\n\nIn R, there are several different values that represent “non-values” like NA, NULL, and NaN. The NA value is the “missing data” value, and it can be best understood as something like “there is a value here in theory, but it’s unknown”. In the example above, where we got NAs from converting a string like “apple” to numeric type, R is basically saying “well, there was a value here, but since I don’t know how to convert it to a number, I’m giving you back the ‘unknown’ value of NA”.\nSince R treats NA values different from other kinds of non-values, this can be very helpful.4\n4 In brief: where an NA value means “exists, but is unknown”, a NULL value means “does not exist”, and a NaN value means not a number, which you can get when you end up with invalid mathematical results, like if you try to get the logarithm of a negative number.But back to the specific issue at hand: when you convert a vector to another type of data, R will typically warn you if you are introducing NA values because of that conversion, but “warnings” in R are just sort of “FYIs”, and don’t prevent you from doing the thing. Converting a vector of data to numeric might be the right thing to do, even if it introduces some missing values (NA values). That’s up to you as the data analyst. The warning is just there to help inform you that you should check where the NAs were produced, in case that indicates a problem with your data.\n\n\n\n\nWith those important side notes out of the way, let’s return to the topic of vectors in general. Since order matters in a vector, you can refer to specific segments of a vector using a few different methods of indexing. Let’s look at a few of the most common.\nFirst, R uses square brackets to indicate an index or subset of most objects, including vectors. Second, unlike many other programming languages, R counts starting from 1, so that (for example), the 1st element of a vector is selected using [1] and the 4th element of a vector is selected using [4].5\n5 This is another great example of R’s purposeful design. There are some solid computer science reasons for why most other programming languages start counting at 0. But R is designed for statisticians and data analysts, and when you’re thinking about numbers and data, starting at 1 just makes a little more intuitive sense. But this can be a minor nuisance for people coming to R from other programming backgrounds.Additionally, if you put a vector of numbers inside the brackets, R gives you back the values at those positions. See the following code for some examples, and play around with making some additional examples to understand how this works. We first create a vector of letters, and then print out some different examples of subsets of that vector using the square bracket notation.\n\nletters &lt;- c(\"a\", \"b\", \"c\", \"d\", \"e\")\nprint(letters[2])\n\n[1] \"b\"\n\nprint(letters[c(1, 3, 5)])\n\n[1] \"a\" \"c\" \"e\"\n\nprint(letters[3:5])\n\n[1] \"c\" \"d\" \"e\"\n\nprint(letters[ ])\n\n[1] \"a\" \"b\" \"c\" \"d\" \"e\"\n\nprint(letters[-3])\n\n[1] \"a\" \"b\" \"d\" \"e\"\n\nprint(letters[c(-3, -5)])\n\n[1] \"a\" \"b\" \"d\"\n\n\nLet’s walk through these different printed values:\n\nThe 2nd element of the letters vector can be referred to as letters[2]\nBy using the vector c(1, 3, 5) inside the brackets, we can get back the 1st, 3rd, and 5th elements.\nAny method of making a vector works inside the brackets. So because 3:5 creates the vector c(3, 4, 5), the third print statement returns back the 3rd, 4th, and 5th elements.\nIf you leave the area in the brackets blank, it returns all of the values in the vector.\nNegative index values exclude values instead, so [-3] means “everything except the 3rd value.”\nAnd finally, you can use a vector of negative numbers to exclude multiple values, so the final print statement above means “everything except the 3rd and 5th values.”\n\nIncidentally, now that you know that indexes are numbers in brackets, run the following code and look at the console print out:\n\nprint(1:100)\n\n  [1]   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n [19]  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n [37]  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n [55]  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n [73]  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n [91]  91  92  93  94  95  96  97  98  99 100\n\n\nIn addition to the values, you can see bracketed numbers all along the left side, starting with [1]. This is basically R’s way of helping you read the output, because these bracketed numbers are telling you which element of the printed vector starts that row. So for example, if you were looking for an NA value, and you saw a console print out that looked like:\n\n[37] 45  82  91   4  13  NA  84  67\n\nThen you would know that the value “45” was the 37th item in the vector (because of the [37]), and you could count over to the NA to figure out that it’s the element [42] in the vector. In other words, those bracketed numbers along the left side are just there for convenience, to help you identify the index of a certain value.\nSo now you should understand what that [1] means whenever you see any printed-out result from R! It’s just indicating the vector position of that result, and when the result is just a single value, the vector may only have a length of 1.\n\n\n\nWhile selecting values from a vector by numeric index can be helpful, it’s usually much more helpful to select values by some kind of condition.\nIn order to help accomplish this, like most other programming languages R has special values TRUE and FALSE that stand for the boolean “true” and “false” values.6 7 R calls these values “logical”-type data. Among other things, these are the values you get back from comparisons, so for example, see what values the following expressions return:\n6 This is another thing that varies a little between programming languages. Virtually every language has a way of expressing true/false values, but they often look different. In R, it’s all-caps TRUE and FALSE. In Python, it’s title-case True and False. In JavaScript, it’s lowercase true and false. In some dialects of Lisp it’s t and nil. And so on.7 R also has “shortcut” values where you can use T and F to stand for TRUE and FALSE, but I highly recommend that you do not use these in practice. This is because it’s actually possible to assign values to T and F as variable names, so if you were perverse enough you could actually assign T &lt;- FALSE. But you cannot assign variable names of TRUE or FALSE, so those value are safe. It’s also a lot easier to visually confuse T and F when you’re skimming code. So don’t be lazy, use the full forms. I’m just telling you this in case you see it in other code somewhere.\nprint(3 &lt; 5) \n\n[1] TRUE\n\nprint(3 &gt; 5)\n\n[1] FALSE\n\n\nWhat is important for us here is that you can use boolean TRUE and FALSE values inside square brackets instead of indexing by number. As an example, let’s think about the numbers from 2 to 10, and think about which ones are prime numbers. Then imagine we had a vector of TRUE and FALSE values that was also 9 elements long, where the TRUE values were in the positions that corresponded to where the other vector had prime numbers. That vector of booleans could be used to get that exact subset inside the square brackets, instead of having to pass numeric indexes.\n\nsome_integers &lt;- c(2, 3, 4, 5, 6, 7, 8, 9, 10)\nprimes &lt;- c(TRUE, TRUE, FALSE, TRUE, FALSE, TRUE, FALSE, FALSE, FALSE)\nsome_integers[primes]\n\n[1] 2 3 5 7\n\n\nWhat this means is that if we can use a condition to create a vector of TRUE and FALSE values, we can use that to get subsets where that condition returns TRUE. This is extremely powerful and useful.\nFor example, let’s imagine we have a long vector of numbers, and we just want to see the numbers that are under a particular threshold. The following code creates a vector of numbers, and then shows how the &lt; comparison can be used to create a vector of TRUE and FALSE values to match the condition.\n\nsample_values &lt;- c(30, 18, 300, 5, 8000, 101, 2, 13)\nsample_values &lt; 100\n\n[1]  TRUE  TRUE FALSE  TRUE FALSE FALSE  TRUE  TRUE\n\n\nAnd the handy thing is that we can use this vector of booleans inside the square brackets of the original vector to get just the items that match that condition:\n\nsubset_under_100 &lt;- sample_values[sample_values &lt; 100]\nprint(subset_under_100)\n\n[1] 30 18  5  2 13\n\n\nFor mnemonic purposes, you can phrase the 1st line above as the: “I want to get the values of the sample_values vector wherever sample_values is less than 100”. Using the “wherever” phrase in your head can be a helpful way to think about what this structure is doing.\nThis way of using booleans is great, because it means we can do all kinds of “search” or subset operations with tons of data without having to know things like the numeric indexes of what we’re looking for.\nNotice that you don’t have to use the same vector for the comparison. It’s often very useful to subset by a different set of values. Take the following example, where there are two vectors of values, one a vector of fruit names, and another a vector of prices that corresponds to those fruits. We can use boolean subsetting to just get back the fruits “wherever the price is greater than 5”.\n\nfruits &lt;- c(\"apple\", \"bananas\", \"kiwi\", \"peaches\", \"raspberries\", \"pears\")\nprices &lt;- c(3.49, 1.79, 6.00, 4.59, 5.99, 4.09)\nprint(fruits[prices &gt; 5])\n\n[1] \"kiwi\"        \"raspberries\"\n\n\nNote that the important thing here is that if you are using a vector of booleans inside square brackets as a way to get a subset, the length of the boolean vector should be the same as the length of the vector you are subsetting. For example, if you have 700 data points, your boolean vector should have 700 TRUE and FALSE values.\n\n\n\nWhat I just said about matching length is true, and is usually the best practice. But in the spirit of R being relatively permissive and flexible, there’s a phenomenon called recycling that I’ll explain, since it sometimes comes up unintentionally. If you give R a short vector where it expects a longer one, then it will repeat or “recycle” the shorter value to try to match the length of the longer one. If it doesn’t recycle evenly, it will sometimes give you an error, but sometimes not. It’s the “sometimes” aspect of this phenomenon that can lead to unexpected issues, if you’re not careful.\nSee the following example code.\n\nfruits &lt;- c(\"apple\", \"bananas\", \"kiwi\", \"peaches\", \"raspberries\", \"pears\")\nprint(fruits[c(TRUE, FALSE)])\n\n[1] \"apple\"       \"kiwi\"        \"raspberries\"\n\nprint(fruits[c(TRUE, FALSE, FALSE, TRUE)])\n\n[1] \"apple\"       \"peaches\"     \"raspberries\"\n\n\nIn the first print statement, we are using a vector of just two logical values, while the length of the fruits vector is 6. What R does is recycle the short vector, so you end up with alternating TRUE and FALSE values, which ends up returning alternating values from the fruits vector. To put it another way, R ends up repeating that c(TRUE, FALSE) vector until it’s long enough to match the fruits vector, so it’s the same as saying:\n\nfruits[c(TRUE, FALSE, TRUE, FALSE, TRUE, FALSE)]\n\nIn the second print statement, the logical vector has a length of 4, which doesn’t go evenly into 6. Never mind that, R will still recycle as much as it can, so after the first sequence of TRUE, FALSE, FALSE, TRUE, it starts another sequence of the same, even though it will only use the first two values before it “fills up” the length of the fruits vector. So you end up with the same effect as if it was a vector of TRUE, FALSE, FALSE, TRUE, TRUE, FALSE.\nThis is sometimes convenient, but it can also produce unwelcome surprises, so it’s something good to be aware of. In practice, I recommend trying to avoid the whole recycling issue by making sure the vectors you’re matching up have the same length. You can always check the length of a vector with the length() function, for example:\n\nprint(length(fruits))\n\n[1] 6\n\nprint(length(c(TRUE, FALSE, FALSE, TRUE)))\n\n[1] 4\n\n\n\n\n\nA final crucial point about vectors in R is that many operations in R are vectorized.8 Not to go too far into the details, but in case you run into discussions of vectorized operations elsewhere, there are basically two kinds of vectorization. One is computationally very efficient, which is why you might see some discussions where people are yelling about always vectorizing, instead of using other methods like for-loops. But there are also cases where it looks like a vectorized operation, but it’s really just a for-loop in disguise, under the hood.\n8 For Pythonistas, this is another property that R vectors share with NumPy ndarrays.This distinction doesn’t really matter unless you are getting deep into performance issues, like if you need to optimize the performance of some code to be able to run more rapidly or more cheaply for a commercial application. But most of the time, and especially for what we are doing in this class, it doesn’t matter all that much.\nWhat is important is that R generally does a good job of letting you apply operations and functions to vectors and get back a vector, and you should take advantage of that. For example, if you wanted to add 5 to a large vector of numbers, you don’t need to write a code that implements a loop, you can just say:\n\nlarge_vector &lt;- large_vector + 5\n\nand R is smart enough to know that you mean you want to add 5 to each element in the vector.\nNotice we already did this when we said prices &gt; 5 in the code above, because the result was that we compared each value of the prices vector to 5.\nMost of the time this is convenient, because it means you can apply some operation or calculation to many things at once, without having to write an explicit loop in your code.\nA slightly different example of “vectorization” (in the broad sense) is when you perform an operation between two vectors. When the vectors are equal length, the operation is done “pairwise” – the first element of vector A is paired with the first element of vector B, and so on. Consider the following examples:\n\nvector_a &lt;- c(1, 4, 2, 6, 8, 9)\nvector_b &lt;- c(5, 2, 1, 7, 7, 9)\n\nprint(vector_a + 5)\n\n[1]  6  9  7 11 13 14\n\nprint(log(vector_a))\n\n[1] 0.0000000 1.3862944 0.6931472 1.7917595 2.0794415 2.1972246\n\nprint(vector_a + vector_b)\n\n[1]  6  6  3 13 15 18\n\nprint(vector_a * vector_b)\n\n[1]  5  8  2 42 56 81\n\nprint(vector_a &lt; vector_b)\n\n[1]  TRUE FALSE FALSE  TRUE FALSE FALSE\n\n\nThe first two print statements are examples of regular vectorization, where you are applying some calculation or transformation to every variable in the vector. So when we say we are “log-transforming a variable” using the log() function, what we really mean is that we are log-transforming each value in the vector representing our variable.\nThe latter three print statements above all show “pairwise” operations, where the first element of one vector is added/multiplied/compared to the first element of the other vector, the second element to the second element, and so on.\nRecycling can also work here, but not quite as permissively as what we saw above with subsetting. See the following examples, and work through the math so you can see what is getting added to what in each line:\n\nvector_a &lt;- c(1, 4, 2, 6, 8, 9)\nvector_c &lt;- c(1, 7)\nvector_d &lt;- c(3, 3, 3, 4)\n\nvector_a + vector_c # recycling works\n\n[1]  2 11  3 13  9 16\n\nvector_a + vector_d # incomplete recycling doesn't work\n\nWarning in vector_a + vector_d: longer object length is not a multiple of\nshorter object length\n\n\n[1]  4  7  5 10 11 12\n\n\nIn short, pairwise operations usually work, operations with recycling can sometimes work, if the length of the smaller vector is a multiple of the length of the longer one, but operations between two vectors where one length is not a multiple of the other usually don’t work.\nThe upshot is that you should think about the length of your vectors, and the best case is when they match in length, but R gives you some flexibility, at the cost of sometimes producing some unexpected behavior if you’re not careful.\nBut being able to perform vectorized operations is a major feature of R, and one we’ll use a lot, even if we don’t actively think about it.\n\n\n\nThis concludes the tutorial on vectors. Next up: data frames!",
    "crumbs": [
      "Home",
      "Working with data in R",
      "Vectors: a basic building block of data in R"
    ]
  },
  {
    "objectID": "R_basics_vectors.html#vectors-variables-and-sequences",
    "href": "R_basics_vectors.html#vectors-variables-and-sequences",
    "title": "R Basics: vectors",
    "section": "",
    "text": "One of the fundamental constructs in data analysis and statistics is the concept of a variable. In the R Fundamentals tutorial, we also discussed a different kind of “variable.” Usually the context will make it clear which one we are talking about, but if we need to be less ambiguous, I will sometimes refer to “data variables” vs. “programming variables.”\nA data variable is a variable in the statistics sense, namely a set of values that corresponds to data on a particular scale, such as a set of years, or length measurements, or dollar amounts, or genders of respondents, or crime rates, or song titles, or flower species, or whatever. A programming variable is the use of a symbol1 that names an object in memory. So when we say something like, “pick a variable from your data set”, we are talking about a “statistics variable,” but when we say something like, “assign this value to a new variable in your code,” we are talking about a “programming variable.”\n1 And by symbol, I mean “set of valid characters.” In R, we can use alphanumeric characters (letters and numbers), plus a couple of other characters like underscores and periods to form a variable name. That variable name is a symbol in this technical sense.Sorry if this feels like weird nitpicking. But there are times when we use similar (or even the same!) words for different concepts in statistics vs. programming, and I just want to call attention to where that happens, in case those terms are creating confusion for you.\nBack to the topic at hand, in R, statistics variables are usually represented by a structure that R calls a vector. In other programming languages, this might be called an array.2\n2 R also has array structures, which are essentially multi-dimensional vectors. This is another aspect of terminology that can be confusing, when programming languages use terms differently. Unfortunately, since we can’t really change how different languages have already named things, the best we can do is try to keep track. For example, R and Python both have things called “lists”, but they have a lot of differences. If you are coming from Python, the closest thing to R’s vector structure is the array from the NumPy library.A vector in R is essentially just a series of values, and by “series”, I mean that there’s an order to them, and the order usually matters. This is typical in data analysis, because the data in a vector might correspond to the order that the data was collected in, or perhaps it is arranged in another way that is meaningful.\nAnother key property of vectors in R, which does match our definition of a statistics variable, is that all of the values in a vector have to match in type. That is, they can all be numbers, or all strings, or all some other type of object, but you can’t mix data types in a vector in R.3\n3 If you want a structure where you can mix types in R, you should use a list. This is something that R lists do have in common with Python lists, if you’re keeping track.These properties make vectors natural ways to represent statistics variables.\nFurthermore, almost any time you generate a simple series or sequence of values (whether those are numeric or some other type), it’s treated as a vector. And because vectors are kind of the “default” data structure in R, R gives you lots of convenient ways to create them.\nFor example, we can use the colon operator : to generate a sequence of integers. The following creates a vector of integers from 1 to 10, inclusive of both. Run this code and modify it until you understand what it’s doing.\n\nshort_vector &lt;- 1:10\nprint(short_vector)\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nThe colon operator is convenient, but there is a function seq() (for “sequence”) that gives us a lot more control over creating a sequenced numeric vector. In this function, you give it a starting value, an ending value, and a value that represents the “step” you take between values. For example, the following creates a sequence from 0 to 1, stepping by 0.1, another sequence from 10 to 30 stepping by 2, and a third sequence from 1 to 100 stepping by 5. To illustrate some of what we discussed in the previous tutorial, I’ll mix up how the arguments are specified, to show you a few different options.\n\nsequence1 &lt;- seq(0, 1, 0.1)\nprint(sequence1)\n\n [1] 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0\n\nsequence2 &lt;- seq(to = 30, by = 2, from = 10)\nprint(sequence2)\n\n [1] 10 12 14 16 18 20 22 24 26 28 30\n\nsequence3 &lt;- seq(1, 100, by = 5)\nprint(sequence3)\n\n [1]  1  6 11 16 21 26 31 36 41 46 51 56 61 66 71 76 81 86 91 96\n\n\nOne more note about the seq() function. In sequence3, we asked it to increment by 5 from 1 to 100. But it only got to 96, because the next value by 5 would be 101, which is beyond the to value. This is just an example that you might want to double-check your sequences if you make them, to confirm that they are giving you the values you want. If we actually wanted a vector that counted by 5’s up to 100, we would want something like seq(0, 100, by = 5) instead.",
    "crumbs": [
      "Home",
      "Working with data in R",
      "Vectors: a basic building block of data in R"
    ]
  },
  {
    "objectID": "R_basics_vectors.html#making-vectors-from-scratch",
    "href": "R_basics_vectors.html#making-vectors-from-scratch",
    "title": "R Basics: vectors",
    "section": "",
    "text": "While ordered sequences are handy, we sometimes want to make vectors out of series of numbers (or other data) that are not necessarily an orderly sequence. For this, R uses a simple function c() (which stands for “concatenate”) that simply converts its arguments into a vector. For example:\n\nsome_numbers &lt;- c(3, 66, 1, 5849, 42, 0.33, pi) # pi is a number in R!\nsome_words &lt;- c(\"person\", \"woman\", \"man\", \"camera\", \"TV\")\n\nBoth some_numbers and some_words are vectors. The point is that just a series of items separated by commas is not automatically interpreted as a vector. If you want to “manually” type in a vector in R, you need to use the c() function to create a vector from its arguments (separated by commas).",
    "crumbs": [
      "Home",
      "Working with data in R",
      "Vectors: a basic building block of data in R"
    ]
  },
  {
    "objectID": "R_basics_vectors.html#vectors-are-homogeneous",
    "href": "R_basics_vectors.html#vectors-are-homogeneous",
    "title": "R Basics: vectors",
    "section": "",
    "text": "As I mentioned above, one crucial aspect of vectors in R is that they are homogeneous, meaning that the entire vector has to contain the same type of data. For example, you can have a vector of numbers, like some_numbers above, or a vector of strings, like some_words above, but you can’t have a mixed vector of some numbers and some strings. However, R doesn’t stop you from trying:\n\nmixed_vector &lt;- c(467, 2, \"apple\", 487, \"three\")\nprint(mixed_vector)\n\n[1] \"467\"   \"2\"     \"apple\" \"487\"   \"three\"\n\n\n\n\nIn some programming languages, something like the above produce an error, but R tries to be helpful by giving you a result back. In this example, all of the numeric values have been coerced into strings. This process of coercion is common throughout R. It is often convenient and helpful, but it can also lead to problems when you’re not careful or if you’re unaware it’s happening.\nOne example you may encounter is that when you read in data, you might find that a column of what should be numbers is not treated as numeric, but rather as characters. This might be because R treats columns as vectors (so they must be homogeneous), and then somewhere in the column there might have been a value that was not numeric (like a value with a stray character in it), so the entire vector was coerced into a character vector. For example, if you have a column of dollar amounts as integers but one amount is listed as the string “not available”, that column may be coerced into a character vector.\nIn short, coercion is a process that R frequently uses to avoid errors by converting the data to the “lowest denominator”, meaning the data type that has the least restrictions. So while the number 1 can be coerced to the character “1”, the word “hello” cannot be coerced to a number.\n\n\n\nBut you can also force R to convert a vector into another data type. There are a bunch of functions that all start with as. that do this, like as.numeric(), as.integer(), as.character(), as.factor(), as.data.frame() and so on. When you use these, R does the best it can. For example, see what happens when we try to force our mixed_vector from above to be numeric:\n\nmixed_vector_num &lt;- as.numeric(mixed_vector)\n\nWarning: NAs introduced by coercion\n\nprint(mixed_vector_num)\n\n[1] 467   2  NA 487  NA\n\n\nWhat happens is that for the values where R has a method for converting that value to a number, it does so. This is why we can get the number 467 from the string \"467\". It’s pretty intuitive to think about taking a string of numeric characters and converting into numeric type data, so this is nice. But R essentially doesn’t know how to convert a character string like “apple” or “three” to numbers, so it substitutes a special NA value if you force those values to be numeric type data. Fortunately, R also gives you a warning message when this happens, just in case you weren’t expect it. This special NA value is important enough to warrant a short excursion.\n\n\n\nIn R, there are several different values that represent “non-values” like NA, NULL, and NaN. The NA value is the “missing data” value, and it can be best understood as something like “there is a value here in theory, but it’s unknown”. In the example above, where we got NAs from converting a string like “apple” to numeric type, R is basically saying “well, there was a value here, but since I don’t know how to convert it to a number, I’m giving you back the ‘unknown’ value of NA”.\nSince R treats NA values different from other kinds of non-values, this can be very helpful.4\n4 In brief: where an NA value means “exists, but is unknown”, a NULL value means “does not exist”, and a NaN value means not a number, which you can get when you end up with invalid mathematical results, like if you try to get the logarithm of a negative number.But back to the specific issue at hand: when you convert a vector to another type of data, R will typically warn you if you are introducing NA values because of that conversion, but “warnings” in R are just sort of “FYIs”, and don’t prevent you from doing the thing. Converting a vector of data to numeric might be the right thing to do, even if it introduces some missing values (NA values). That’s up to you as the data analyst. The warning is just there to help inform you that you should check where the NAs were produced, in case that indicates a problem with your data.",
    "crumbs": [
      "Home",
      "Working with data in R",
      "Vectors: a basic building block of data in R"
    ]
  },
  {
    "objectID": "R_basics_vectors.html#selecting-parts-of-vectors-indexing-and-subsetting",
    "href": "R_basics_vectors.html#selecting-parts-of-vectors-indexing-and-subsetting",
    "title": "R Basics: vectors",
    "section": "",
    "text": "With those important side notes out of the way, let’s return to the topic of vectors in general. Since order matters in a vector, you can refer to specific segments of a vector using a few different methods of indexing. Let’s look at a few of the most common.\nFirst, R uses square brackets to indicate an index or subset of most objects, including vectors. Second, unlike many other programming languages, R counts starting from 1, so that (for example), the 1st element of a vector is selected using [1] and the 4th element of a vector is selected using [4].5\n5 This is another great example of R’s purposeful design. There are some solid computer science reasons for why most other programming languages start counting at 0. But R is designed for statisticians and data analysts, and when you’re thinking about numbers and data, starting at 1 just makes a little more intuitive sense. But this can be a minor nuisance for people coming to R from other programming backgrounds.Additionally, if you put a vector of numbers inside the brackets, R gives you back the values at those positions. See the following code for some examples, and play around with making some additional examples to understand how this works. We first create a vector of letters, and then print out some different examples of subsets of that vector using the square bracket notation.\n\nletters &lt;- c(\"a\", \"b\", \"c\", \"d\", \"e\")\nprint(letters[2])\n\n[1] \"b\"\n\nprint(letters[c(1, 3, 5)])\n\n[1] \"a\" \"c\" \"e\"\n\nprint(letters[3:5])\n\n[1] \"c\" \"d\" \"e\"\n\nprint(letters[ ])\n\n[1] \"a\" \"b\" \"c\" \"d\" \"e\"\n\nprint(letters[-3])\n\n[1] \"a\" \"b\" \"d\" \"e\"\n\nprint(letters[c(-3, -5)])\n\n[1] \"a\" \"b\" \"d\"\n\n\nLet’s walk through these different printed values:\n\nThe 2nd element of the letters vector can be referred to as letters[2]\nBy using the vector c(1, 3, 5) inside the brackets, we can get back the 1st, 3rd, and 5th elements.\nAny method of making a vector works inside the brackets. So because 3:5 creates the vector c(3, 4, 5), the third print statement returns back the 3rd, 4th, and 5th elements.\nIf you leave the area in the brackets blank, it returns all of the values in the vector.\nNegative index values exclude values instead, so [-3] means “everything except the 3rd value.”\nAnd finally, you can use a vector of negative numbers to exclude multiple values, so the final print statement above means “everything except the 3rd and 5th values.”\n\nIncidentally, now that you know that indexes are numbers in brackets, run the following code and look at the console print out:\n\nprint(1:100)\n\n  [1]   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n [19]  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n [37]  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n [55]  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n [73]  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n [91]  91  92  93  94  95  96  97  98  99 100\n\n\nIn addition to the values, you can see bracketed numbers all along the left side, starting with [1]. This is basically R’s way of helping you read the output, because these bracketed numbers are telling you which element of the printed vector starts that row. So for example, if you were looking for an NA value, and you saw a console print out that looked like:\n\n[37] 45  82  91   4  13  NA  84  67\n\nThen you would know that the value “45” was the 37th item in the vector (because of the [37]), and you could count over to the NA to figure out that it’s the element [42] in the vector. In other words, those bracketed numbers along the left side are just there for convenience, to help you identify the index of a certain value.\nSo now you should understand what that [1] means whenever you see any printed-out result from R! It’s just indicating the vector position of that result, and when the result is just a single value, the vector may only have a length of 1.",
    "crumbs": [
      "Home",
      "Working with data in R",
      "Vectors: a basic building block of data in R"
    ]
  },
  {
    "objectID": "R_basics_vectors.html#selecting-vector-values-with-booleanslogicals",
    "href": "R_basics_vectors.html#selecting-vector-values-with-booleanslogicals",
    "title": "R Basics: vectors",
    "section": "",
    "text": "While selecting values from a vector by numeric index can be helpful, it’s usually much more helpful to select values by some kind of condition.\nIn order to help accomplish this, like most other programming languages R has special values TRUE and FALSE that stand for the boolean “true” and “false” values.6 7 R calls these values “logical”-type data. Among other things, these are the values you get back from comparisons, so for example, see what values the following expressions return:\n6 This is another thing that varies a little between programming languages. Virtually every language has a way of expressing true/false values, but they often look different. In R, it’s all-caps TRUE and FALSE. In Python, it’s title-case True and False. In JavaScript, it’s lowercase true and false. In some dialects of Lisp it’s t and nil. And so on.7 R also has “shortcut” values where you can use T and F to stand for TRUE and FALSE, but I highly recommend that you do not use these in practice. This is because it’s actually possible to assign values to T and F as variable names, so if you were perverse enough you could actually assign T &lt;- FALSE. But you cannot assign variable names of TRUE or FALSE, so those value are safe. It’s also a lot easier to visually confuse T and F when you’re skimming code. So don’t be lazy, use the full forms. I’m just telling you this in case you see it in other code somewhere.\nprint(3 &lt; 5) \n\n[1] TRUE\n\nprint(3 &gt; 5)\n\n[1] FALSE\n\n\nWhat is important for us here is that you can use boolean TRUE and FALSE values inside square brackets instead of indexing by number. As an example, let’s think about the numbers from 2 to 10, and think about which ones are prime numbers. Then imagine we had a vector of TRUE and FALSE values that was also 9 elements long, where the TRUE values were in the positions that corresponded to where the other vector had prime numbers. That vector of booleans could be used to get that exact subset inside the square brackets, instead of having to pass numeric indexes.\n\nsome_integers &lt;- c(2, 3, 4, 5, 6, 7, 8, 9, 10)\nprimes &lt;- c(TRUE, TRUE, FALSE, TRUE, FALSE, TRUE, FALSE, FALSE, FALSE)\nsome_integers[primes]\n\n[1] 2 3 5 7\n\n\nWhat this means is that if we can use a condition to create a vector of TRUE and FALSE values, we can use that to get subsets where that condition returns TRUE. This is extremely powerful and useful.\nFor example, let’s imagine we have a long vector of numbers, and we just want to see the numbers that are under a particular threshold. The following code creates a vector of numbers, and then shows how the &lt; comparison can be used to create a vector of TRUE and FALSE values to match the condition.\n\nsample_values &lt;- c(30, 18, 300, 5, 8000, 101, 2, 13)\nsample_values &lt; 100\n\n[1]  TRUE  TRUE FALSE  TRUE FALSE FALSE  TRUE  TRUE\n\n\nAnd the handy thing is that we can use this vector of booleans inside the square brackets of the original vector to get just the items that match that condition:\n\nsubset_under_100 &lt;- sample_values[sample_values &lt; 100]\nprint(subset_under_100)\n\n[1] 30 18  5  2 13\n\n\nFor mnemonic purposes, you can phrase the 1st line above as the: “I want to get the values of the sample_values vector wherever sample_values is less than 100”. Using the “wherever” phrase in your head can be a helpful way to think about what this structure is doing.\nThis way of using booleans is great, because it means we can do all kinds of “search” or subset operations with tons of data without having to know things like the numeric indexes of what we’re looking for.\nNotice that you don’t have to use the same vector for the comparison. It’s often very useful to subset by a different set of values. Take the following example, where there are two vectors of values, one a vector of fruit names, and another a vector of prices that corresponds to those fruits. We can use boolean subsetting to just get back the fruits “wherever the price is greater than 5”.\n\nfruits &lt;- c(\"apple\", \"bananas\", \"kiwi\", \"peaches\", \"raspberries\", \"pears\")\nprices &lt;- c(3.49, 1.79, 6.00, 4.59, 5.99, 4.09)\nprint(fruits[prices &gt; 5])\n\n[1] \"kiwi\"        \"raspberries\"\n\n\nNote that the important thing here is that if you are using a vector of booleans inside square brackets as a way to get a subset, the length of the boolean vector should be the same as the length of the vector you are subsetting. For example, if you have 700 data points, your boolean vector should have 700 TRUE and FALSE values.",
    "crumbs": [
      "Home",
      "Working with data in R",
      "Vectors: a basic building block of data in R"
    ]
  },
  {
    "objectID": "R_basics_vectors.html#value-recycling",
    "href": "R_basics_vectors.html#value-recycling",
    "title": "R Basics: vectors",
    "section": "",
    "text": "What I just said about matching length is true, and is usually the best practice. But in the spirit of R being relatively permissive and flexible, there’s a phenomenon called recycling that I’ll explain, since it sometimes comes up unintentionally. If you give R a short vector where it expects a longer one, then it will repeat or “recycle” the shorter value to try to match the length of the longer one. If it doesn’t recycle evenly, it will sometimes give you an error, but sometimes not. It’s the “sometimes” aspect of this phenomenon that can lead to unexpected issues, if you’re not careful.\nSee the following example code.\n\nfruits &lt;- c(\"apple\", \"bananas\", \"kiwi\", \"peaches\", \"raspberries\", \"pears\")\nprint(fruits[c(TRUE, FALSE)])\n\n[1] \"apple\"       \"kiwi\"        \"raspberries\"\n\nprint(fruits[c(TRUE, FALSE, FALSE, TRUE)])\n\n[1] \"apple\"       \"peaches\"     \"raspberries\"\n\n\nIn the first print statement, we are using a vector of just two logical values, while the length of the fruits vector is 6. What R does is recycle the short vector, so you end up with alternating TRUE and FALSE values, which ends up returning alternating values from the fruits vector. To put it another way, R ends up repeating that c(TRUE, FALSE) vector until it’s long enough to match the fruits vector, so it’s the same as saying:\n\nfruits[c(TRUE, FALSE, TRUE, FALSE, TRUE, FALSE)]\n\nIn the second print statement, the logical vector has a length of 4, which doesn’t go evenly into 6. Never mind that, R will still recycle as much as it can, so after the first sequence of TRUE, FALSE, FALSE, TRUE, it starts another sequence of the same, even though it will only use the first two values before it “fills up” the length of the fruits vector. So you end up with the same effect as if it was a vector of TRUE, FALSE, FALSE, TRUE, TRUE, FALSE.\nThis is sometimes convenient, but it can also produce unwelcome surprises, so it’s something good to be aware of. In practice, I recommend trying to avoid the whole recycling issue by making sure the vectors you’re matching up have the same length. You can always check the length of a vector with the length() function, for example:\n\nprint(length(fruits))\n\n[1] 6\n\nprint(length(c(TRUE, FALSE, FALSE, TRUE)))\n\n[1] 4",
    "crumbs": [
      "Home",
      "Working with data in R",
      "Vectors: a basic building block of data in R"
    ]
  },
  {
    "objectID": "R_basics_vectors.html#vector-operations",
    "href": "R_basics_vectors.html#vector-operations",
    "title": "R Basics: vectors",
    "section": "",
    "text": "A final crucial point about vectors in R is that many operations in R are vectorized.8 Not to go too far into the details, but in case you run into discussions of vectorized operations elsewhere, there are basically two kinds of vectorization. One is computationally very efficient, which is why you might see some discussions where people are yelling about always vectorizing, instead of using other methods like for-loops. But there are also cases where it looks like a vectorized operation, but it’s really just a for-loop in disguise, under the hood.\n8 For Pythonistas, this is another property that R vectors share with NumPy ndarrays.This distinction doesn’t really matter unless you are getting deep into performance issues, like if you need to optimize the performance of some code to be able to run more rapidly or more cheaply for a commercial application. But most of the time, and especially for what we are doing in this class, it doesn’t matter all that much.\nWhat is important is that R generally does a good job of letting you apply operations and functions to vectors and get back a vector, and you should take advantage of that. For example, if you wanted to add 5 to a large vector of numbers, you don’t need to write a code that implements a loop, you can just say:\n\nlarge_vector &lt;- large_vector + 5\n\nand R is smart enough to know that you mean you want to add 5 to each element in the vector.\nNotice we already did this when we said prices &gt; 5 in the code above, because the result was that we compared each value of the prices vector to 5.\nMost of the time this is convenient, because it means you can apply some operation or calculation to many things at once, without having to write an explicit loop in your code.\nA slightly different example of “vectorization” (in the broad sense) is when you perform an operation between two vectors. When the vectors are equal length, the operation is done “pairwise” – the first element of vector A is paired with the first element of vector B, and so on. Consider the following examples:\n\nvector_a &lt;- c(1, 4, 2, 6, 8, 9)\nvector_b &lt;- c(5, 2, 1, 7, 7, 9)\n\nprint(vector_a + 5)\n\n[1]  6  9  7 11 13 14\n\nprint(log(vector_a))\n\n[1] 0.0000000 1.3862944 0.6931472 1.7917595 2.0794415 2.1972246\n\nprint(vector_a + vector_b)\n\n[1]  6  6  3 13 15 18\n\nprint(vector_a * vector_b)\n\n[1]  5  8  2 42 56 81\n\nprint(vector_a &lt; vector_b)\n\n[1]  TRUE FALSE FALSE  TRUE FALSE FALSE\n\n\nThe first two print statements are examples of regular vectorization, where you are applying some calculation or transformation to every variable in the vector. So when we say we are “log-transforming a variable” using the log() function, what we really mean is that we are log-transforming each value in the vector representing our variable.\nThe latter three print statements above all show “pairwise” operations, where the first element of one vector is added/multiplied/compared to the first element of the other vector, the second element to the second element, and so on.\nRecycling can also work here, but not quite as permissively as what we saw above with subsetting. See the following examples, and work through the math so you can see what is getting added to what in each line:\n\nvector_a &lt;- c(1, 4, 2, 6, 8, 9)\nvector_c &lt;- c(1, 7)\nvector_d &lt;- c(3, 3, 3, 4)\n\nvector_a + vector_c # recycling works\n\n[1]  2 11  3 13  9 16\n\nvector_a + vector_d # incomplete recycling doesn't work\n\nWarning in vector_a + vector_d: longer object length is not a multiple of\nshorter object length\n\n\n[1]  4  7  5 10 11 12\n\n\nIn short, pairwise operations usually work, operations with recycling can sometimes work, if the length of the smaller vector is a multiple of the length of the longer one, but operations between two vectors where one length is not a multiple of the other usually don’t work.\nThe upshot is that you should think about the length of your vectors, and the best case is when they match in length, but R gives you some flexibility, at the cost of sometimes producing some unexpected behavior if you’re not careful.\nBut being able to perform vectorized operations is a major feature of R, and one we’ll use a lot, even if we don’t actively think about it.",
    "crumbs": [
      "Home",
      "Working with data in R",
      "Vectors: a basic building block of data in R"
    ]
  },
  {
    "objectID": "R_basics_vectors.html#next-steps",
    "href": "R_basics_vectors.html#next-steps",
    "title": "R Basics: vectors",
    "section": "",
    "text": "This concludes the tutorial on vectors. Next up: data frames!",
    "crumbs": [
      "Home",
      "Working with data in R",
      "Vectors: a basic building block of data in R"
    ]
  },
  {
    "objectID": "ggplot2_basics.html",
    "href": "ggplot2_basics.html",
    "title": "Getting started with ggplot2",
    "section": "",
    "text": "The ggplot2 package is an extremely popular package for creating data visualizations in R. It is not merely a method for creating standard plots, but an entire framework for creating a huge hage of possible graphs and plots. It comes with sensible defaults so that it is easy to make good-looking plots with minimal work, but it also offers a very high level of control in the details of every aspect of your graphics.\n\n\n\nBase R1 actually comes with a lot of graphical capability. It is quite possible to make effective and beautiful data visualizations just with those tools. However, beyond a few basic plots, the difficulty curve can become very steep, and there are some serious limitations on how these graphics can be modified programmatically.\n1 The standard set of packages that comes with a base installation of R includes a graphics package, and some plotting functions are also in the base package.Around the beginning of the millenium(!), Paul Murrell built an entirely new system for generating graphics in R in the grid package. This package built up an entirely new set of primitives for how graphical objects could be represented, manipulated, and displayed, and after a few years this package was included in R as a base package.\nOne of the goals of grid was to construct a framework that other developers could build on top of, and this goal was definitely achieved. Deepayan Sarkar built the lattice package thanks to grid, and this was a kind of turning point in enabling a whole new wave of development. So when Hadley Wickham implemented the prototype2 of ggplot2, building on top of the grid package was a perfect fit.\n2 You might wonder where the “2” comes from in the name ggplot2. There was an initial ggplot package – the first implementation, based on Wickham’s PhD dissertation. When it was re-implemented from the ground up, Wickham chose to name this new incarnation ggplot2. So even though it’s been a very long time since there was a ggplot package available, and many significant version chances in the development of ggplot2, the name ggplot2 has stuck probably forever.\n\n\nWickham’s goal was to implement a system based on Leland Wilkinson’s influential book, A Grammar of Graphics.3 Wilkinson’s main innovation was to put together an entire system and “language” of primitives having to do with data visualization. This “grammar” could then serve as the basis for designing new sets of visualizations in a cohesive way. In other words, Wilkinson proposed a new set of building blocks to help organize and describe the construction of new data visualizations.\n3 Wilkinson himself was responsible for many influential software packages as well. His SYSTAT system formed the basis of the popular SPSS statistical software, and he worked as a vice president of Tableau.This “building block” concept is arguably one of the main reasons for ggplot2’s success, because it makes it easier to build visualizations conceptually, and to experiment with new combinations and formulations of previous patterns.",
    "crumbs": [
      "Home",
      "Graphical Exploratory Data Analysis",
      "Getting started with the ggplot2 package"
    ]
  },
  {
    "objectID": "ggplot2_basics.html#overview",
    "href": "ggplot2_basics.html#overview",
    "title": "Getting started with ggplot2",
    "section": "",
    "text": "The ggplot2 package is an extremely popular package for creating data visualizations in R. It is not merely a method for creating standard plots, but an entire framework for creating a huge hage of possible graphs and plots. It comes with sensible defaults so that it is easy to make good-looking plots with minimal work, but it also offers a very high level of control in the details of every aspect of your graphics.",
    "crumbs": [
      "Home",
      "Graphical Exploratory Data Analysis",
      "Getting started with the ggplot2 package"
    ]
  },
  {
    "objectID": "ggplot2_basics.html#some-history-and-context",
    "href": "ggplot2_basics.html#some-history-and-context",
    "title": "Getting started with ggplot2",
    "section": "",
    "text": "Base R1 actually comes with a lot of graphical capability. It is quite possible to make effective and beautiful data visualizations just with those tools. However, beyond a few basic plots, the difficulty curve can become very steep, and there are some serious limitations on how these graphics can be modified programmatically.\n1 The standard set of packages that comes with a base installation of R includes a graphics package, and some plotting functions are also in the base package.Around the beginning of the millenium(!), Paul Murrell built an entirely new system for generating graphics in R in the grid package. This package built up an entirely new set of primitives for how graphical objects could be represented, manipulated, and displayed, and after a few years this package was included in R as a base package.\nOne of the goals of grid was to construct a framework that other developers could build on top of, and this goal was definitely achieved. Deepayan Sarkar built the lattice package thanks to grid, and this was a kind of turning point in enabling a whole new wave of development. So when Hadley Wickham implemented the prototype2 of ggplot2, building on top of the grid package was a perfect fit.\n2 You might wonder where the “2” comes from in the name ggplot2. There was an initial ggplot package – the first implementation, based on Wickham’s PhD dissertation. When it was re-implemented from the ground up, Wickham chose to name this new incarnation ggplot2. So even though it’s been a very long time since there was a ggplot package available, and many significant version chances in the development of ggplot2, the name ggplot2 has stuck probably forever.",
    "crumbs": [
      "Home",
      "Graphical Exploratory Data Analysis",
      "Getting started with the ggplot2 package"
    ]
  },
  {
    "objectID": "ggplot2_basics.html#a-grammar-of-graphics",
    "href": "ggplot2_basics.html#a-grammar-of-graphics",
    "title": "Getting started with ggplot2",
    "section": "",
    "text": "Wickham’s goal was to implement a system based on Leland Wilkinson’s influential book, A Grammar of Graphics.3 Wilkinson’s main innovation was to put together an entire system and “language” of primitives having to do with data visualization. This “grammar” could then serve as the basis for designing new sets of visualizations in a cohesive way. In other words, Wilkinson proposed a new set of building blocks to help organize and describe the construction of new data visualizations.\n3 Wilkinson himself was responsible for many influential software packages as well. His SYSTAT system formed the basis of the popular SPSS statistical software, and he worked as a vice president of Tableau.This “building block” concept is arguably one of the main reasons for ggplot2’s success, because it makes it easier to build visualizations conceptually, and to experiment with new combinations and formulations of previous patterns.",
    "crumbs": [
      "Home",
      "Graphical Exploratory Data Analysis",
      "Getting started with the ggplot2 package"
    ]
  },
  {
    "objectID": "ggplot2_basics.html#the-concept-and-syntax-of-layers",
    "href": "ggplot2_basics.html#the-concept-and-syntax-of-layers",
    "title": "Getting started with ggplot2",
    "section": "The concept (and syntax) of layers",
    "text": "The concept (and syntax) of layers\nThe most confusing thing when starting to use ggplot2 is how it builds up plots in layers, both because this abstracts somewhat from how we might normally think about data plots, but also because even the syntax itself is a little idiosynchratic compared to other things in R.\nThe graphic below depicts how the various aspects of ggplot2 are “layered” to create a plot.\n\n\n\nggplot2 layers\n\n\nAt the base is the data, which is maybe obvious, but ggplot2 does take a kind of perspective here that is good to keep in mind. In short, ggplot2 works best when you have your data in a tidy data frame, where the variables of interest are arranged in columns. This segues into the next conceptual layer, the mapping. The core idea here is that you essentially need to map variables to graphical dimensions. The term for graphical dimension that comes from Wilkinson’s work is aesthetic.\nThese two layers are captured with the ggplot() function4. The first argument is the data frame, and the second argument is the mapping, which is created using the aes() function, which stands for aesthetic. In the following code, we are setting up a mapping for the classic iris dataset from Fisher (1936), where values on the x-axis are mapped to petal length, and values on the y-axis are mapped to petal width.5\n4 As a reminder: even though the package is called ggplot2, the core function is ggplot()5 This data set is perhaps a little over-used, but it comes pre-loaded in R, and since it is so well known, visualizing it is almost like a “hello world” for visualization. You can see details by running ?iris in R.\nlibrary(ggplot2)\nggplot(data = iris, aes(x = Petal.Length, y = Petal.Width))\n\n\n\n\nsetting up the initial x-y mapping\n\n\n\n\nWhy didn’t this plot show anything? At this point, we have only really set up the mapping, where we want the x-axis to depend on the Petal.Length column of the iris data frame and the y-axis to depend on the Petal.Width column. But we haven’t yet specified what exactly we should draw. In other words, we’ve set up the x-y coordinate system of the plot, but we haven’t given the data a shape yet, so all we see is the plot set up with axes and labels.\nBut note that this is already helpful, because ggplot2 provides axis labels from the column names, and provides some initial choices for how to display values on each axis, with a sensible number of tick marks.\nSo the next step is to add a geom layer, which is the ggplot2 term for “shape to draw.” Some geoms are more “primitive”, simply drawing a shape with the specified dimensions, but others are more complex by performing other transformations or operations as part of rendering the graphic. But the gist is that the geoms are essentially the things that “draw” the data.\nHere, let’s just use the simple geom_point() which draws points for each x-y combination.\n\n1ggplot(iris, aes(Petal.Length, Petal.Width)) + geom_point()\n\n\n1\n\nI have left off the argument names, to make the code more compact, just like with any standard R function. Note that data is the first argument of ggplot() and x and y are the first two default arguments of aes(), in that order.\n\n\n\n\n\n\n\nbasic scatterplot\n\n\n\n\nThis kind of plot is typically known as a “scatterplot”, but the point here is that in ggplot2, for many plot types, we simply build them up from a set of primitives. In this case, geom_point() is just a way to draw dots with x and y values.\nIf we instead wanted to plot a histogram of the Petal.Length variable, we would only need to supply an x mapping in the aes() function, because histograms only require a single variable. Then the geom_histogram() does all the work, in creating bins and displaying bars based on the number of data points in each bin. This is an example of a geom that does a fair amount of “behind the scenes” work in order to draw the shape.\n\nggplot(iris, aes(Petal.Length)) + geom_histogram()\n\n\n\n\nsimple histogram",
    "crumbs": [
      "Home",
      "Graphical Exploratory Data Analysis",
      "Getting started with the ggplot2 package"
    ]
  },
  {
    "objectID": "ggplot2_basics.html#adding-layers",
    "href": "ggplot2_basics.html#adding-layers",
    "title": "Getting started with ggplot2",
    "section": "Adding layers",
    "text": "Adding layers\nAs you can see from our initial examples, ggplot2 takes the concept of “adding layers” quite literally in the code, because you use a + symbol to combine each layer of the plot. Note that each of the layers has its own function. For example, the geom_point() and geom_histogram() in the code above are not inside the ggplot() function, but separate, and the results of these functions are “added” to the result of the ggplot() function. This syntax is a little unusual for how things normally look in R, so I just want to draw your attention to it.\nHowever, once we wrap our head around the concepts of the graph “layers”, this syntax makes a lot of sense. So every plot starts with a ggplot() call that establishes the data and some initiap mappings, and then with each +, we can add a new layer. In practice, it can be helpful to put each new layer on a new line in our code, to make it a little easier to read. Just make sure that each line ends with that + symbol that tells R that will still have more layers to add.",
    "crumbs": [
      "Home",
      "Graphical Exploratory Data Analysis",
      "Getting started with the ggplot2 package"
    ]
  },
  {
    "objectID": "ggplot2_basics.html#adding-geoms",
    "href": "ggplot2_basics.html#adding-geoms",
    "title": "Getting started with ggplot2",
    "section": "Adding geoms",
    "text": "Adding geoms\nBy adding layers, we can add additional geoms in order to easily add more to what is being visualized in our plot. For example, there is also a “rug” geom that creates what is often called a “rug plot”, but is literally just some lines drawn on the axis margins for each value along that axis. This can help give a sense of the distributions of the x and y values separately, and can be a nice enhancement for a plain scatterplot. In ggplot2, all we need to do is to add geom_rug() as an additional layer to our previous scatterplot code.6\n6 As an aside, this particular rug plot is not all that helpful, because many values in this data set overlap (i.e., have the exact same values), so in practice, many of the “rug lines” are plotted on top of each other, which conceals the distribution information somewhat.\nggplot(iris, aes(Petal.Length, Petal.Width)) + \n    geom_point() +\n    geom_rug()\n\n\n\n\nscatterplot with rug plots on the x and y axes",
    "crumbs": [
      "Home",
      "Graphical Exploratory Data Analysis",
      "Getting started with the ggplot2 package"
    ]
  },
  {
    "objectID": "ggplot2_basics.html#adding-geoms-with-more-mappings-mappings-with-and-without-aes",
    "href": "ggplot2_basics.html#adding-geoms-with-more-mappings-mappings-with-and-without-aes",
    "title": "Getting started with ggplot2",
    "section": "Adding geoms with more mappings, mappings with and without aes()",
    "text": "Adding geoms with more mappings, mappings with and without aes()\nAnother example of geoms that is handy as an additional layer are the “hline” and “vline” geoms, which allow us to draw horizontal and vertical lines. These are often useful as a kind of annotation, if we want to highlight certain values as cut-offs or mid-points or other kinds or reference values. But when you add geoms, you may need to add more mappings. For example, geom_vline() does not have an x mapping, but it does need an xintercept mapping, because the line is essentially drawn at a single x value that will intersect with the x-axis.\nFurthermore, when you add mappings, you have two choices. On the one hand, you can map graphical properties to a constant, like if we simply want to specify that we want a vertical line at the value of x = 2.5. In this case, these are specified as simple arguments inside the geom. However, we may also want to map a graphical property to something in our data, and by definition a data-graphics mapping is an aesthetic, so we need to put this mapping inside of another aes() function.\nAs an example, let’s add two vertical lines to our iris scatterplot. First, let’s add a line that simply at x = 2.5, maybe because we want to pick a spot in the middle of the apparent “gap” in x-values. Second, let’s add a line that is at the mean value of Petal.Length. Because this second one is a mapping with our data, we should put it inside aes().\n\nggplot(iris, aes(Petal.Length, Petal.Width)) + \n    geom_point() +\n    geom_vline(xintercept = 2.5) +\n    geom_vline(aes(xintercept = mean(Petal.Length)))\n\n\n\n\nscatterplot with vertical lines\n\n\n\n\nLet’s also distinguish these lines by changing their colors. Color is another graphical property, so we can either map it to data or not. But in this case, we just want the “separation” line to be red and the “mean” line to be blue, so we can set those values as arguments in geom_vline(). Because we are setting colors to specific values and not mapping them to some variable in our data, both of these need to be outside of any aes() functions. In other words, any data-graphics mappings are aesthetics and need to be inside aes(), but if it’s not a data-graphic mapping, it should not be inside aes().\n\nggplot(iris, aes(Petal.Length, Petal.Width)) + \n    geom_point() +\n    geom_vline(xintercept = 2.5, color = \"red\") +\n    geom_vline(aes(xintercept = mean(Petal.Length)), color = \"blue\")\n\n\n\n\nadding color to the vertical lines",
    "crumbs": [
      "Home",
      "Graphical Exploratory Data Analysis",
      "Getting started with the ggplot2 package"
    ]
  },
  {
    "objectID": "ggplot2_basics.html#scales-as-layers",
    "href": "ggplot2_basics.html#scales-as-layers",
    "title": "Getting started with ggplot2",
    "section": "Scales as layers",
    "text": "Scales as layers\nSo far we have only looked at geoms as layers. However, recall this graphic:\n\n\n\nggplot2 layers\n\n\nIn this diagram, the “layers” layer refers to the geoms. But we also have scales, facets, coordinates, and theme. We won’t walk through each of these here, but let’s look at scales and theme.\nThe term scales basically refers to the details of an aesthetic. For example, we set up a mapping between values on the x-axis and Petal.Length values from our data. This is the aesthetic, but there are a lot of details about how that mapping is displayed, and these details are captured by the scale.\nIn more concrete terms, ggplot2 has a series of scale functions that you can add as layers to the plot code, and the arguments of these functions change how the axis or dimension is displayed. One common use is to change the label on the axis, because frequently our variable names are not very “pretty”. It’s good to have the variable name displayed as a default, because it helps us keep track of what exact column is being shown in the data. But if we want to share the graph for other audiences, we might want to make a “prettier” or more informative label.\nBut we can change other properties of the scale as well. One example is setting the breaks of the axis, which determines which values are labeled with tick marks on the axis. So far, our plots have spread the x-axis values out by 2, but perhaps we would like tick marks every 1 cm of petal length.\nThe code below uses two scale layers to change the names of the axes, but also the breaks on the x-axis:\n\nggplot(iris, aes(Petal.Length, Petal.Width)) + \n    geom_point() +\n    scale_y_continuous(name = \"petal width\") +\n    scale_x_continuous(name = \"petal length\", breaks = 1:7)\n\n\n\n\nusing scale functions to adjust axis properties",
    "crumbs": [
      "Home",
      "Graphical Exploratory Data Analysis",
      "Getting started with the ggplot2 package"
    ]
  },
  {
    "objectID": "ggplot2_basics.html#theme-as-a-layer",
    "href": "ggplot2_basics.html#theme-as-a-layer",
    "title": "Getting started with ggplot2",
    "section": "Theme as a layer",
    "text": "Theme as a layer\nWhere the scale functions can modify the display of the axes (and other dimension like color), there are a lot of other “background” graphical properties. For example, the default ggplot2 theme uses a light gray background with “major” white grid lines at the axis breaks, and thinner “minor” grid lines halfway between each major grid line. In order to change the appearance of this grid background, you can use the theme() layer. The theme() layer can also modify other aspects of how things are displayed, like the fonts, text sizes, and so on.\nThe good thing is that you can exercise a fine degree of control over every one of these elements, but the downside is that managing these details can start to feel very fiddly and annoying. Fortunately, in addition to the default theme, ggplot2 comes with several other “overall” themes to choose from, and you can also define your own themes if you would like to set up a consistent graphical “look” across multiple plots.\nThe code below shows an example of the “minimal” theme, which is another nice default.\n\nggplot(iris, aes(Petal.Length, Petal.Width)) + \n    geom_point() +\n    theme_minimal()\n\n\n\n\napplying a simple theme",
    "crumbs": [
      "Home",
      "Graphical Exploratory Data Analysis",
      "Getting started with the ggplot2 package"
    ]
  },
  {
    "objectID": "ggplot2_basics.html#other-convenience-layers",
    "href": "ggplot2_basics.html#other-convenience-layers",
    "title": "Getting started with ggplot2",
    "section": "Other “convenience” layers",
    "text": "Other “convenience” layers\nThere are a number of other tweaks that you can make using scales or theme, but sometimes those can be a little cumbersome, so the authors of ggplot2 have added some other convenience functions to do specific things. Some of these have been superceded over time, so if you find examples or other documentation elsewhere, you may see different options.\nOne example is that currently, there is a recommended labs() function that is intended to control all of the label text in a unified way. This includes things like the plot title, subtitle, caption, and alt-text (useful for displaying on websites, for example). You can also use this function to change axis labels.\nThe following shows an example using a labs() layer to set the title and axis labels, and then a theme() layer to adjust the font and size of the title text.\n\nggplot(iris, aes(Petal.Length, Petal.Width)) + \n    geom_point() +\n    labs(title = \"Example scatterplot of the classic iris data\",\n         x = \"petal length (cm)\", y = \"petal length (cm)\") +\n    theme(plot.title = element_text(family = \"serif\", face = \"italic\", size = 20))\n\n\n\n\nadjusting labels and modifying the text properties of the title label",
    "crumbs": [
      "Home",
      "Graphical Exploratory Data Analysis",
      "Getting started with the ggplot2 package"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "under_construction.html",
    "href": "under_construction.html",
    "title": "Work in progress",
    "section": "",
    "text": "This section is currently under construction."
  },
  {
    "objectID": "R_basics_dataframes.html",
    "href": "R_basics_dataframes.html",
    "title": "R Basics: data frames and reading simple files",
    "section": "",
    "text": "In this tutorial, we will discuss how R implements the concept of a data frame. In a nutshell, data frames are like a spreadsheet or database table, where data is arranged into columns and rows.\nThe good news is that data frames are very common in R, and they are implemented in a really useful way. R makes data frames easy to work with and manipulate, and many R functions take advantage of this. When in doubt, get your data into a data frame!",
    "crumbs": [
      "Home",
      "Working with data in R",
      "Data Frames: the most useful data structure in R"
    ]
  },
  {
    "objectID": "R_basics_dataframes.html#quick-practice",
    "href": "R_basics_dataframes.html#quick-practice",
    "title": "R Basics: data frames and reading simple files",
    "section": "Quick practice",
    "text": "Quick practice\nSee if you can pull out the following values:\n\nThe 21st through 24th values from the “grams” column. Answer: 244, 271, 243, 230\nThe values from the “feed” column from the 20th, 40th, and 60th rows. Answer: “linseed”, “sunflower”, and “casein”\nThe 35th through 38th rows, both columns. Answer: (table below)\n\n\n\n\ngrams\nfeed\n\n\n\n\n158\nsoybean\n\n\n248\nsoybean\n\n\n423\nsunflower\n\n\n340\nsunflower\n\n\n\nFor more practice, see how many different ways you can think of pulling out these values, using the bracket notation and the $ notation.",
    "crumbs": [
      "Home",
      "Working with data in R",
      "Data Frames: the most useful data structure in R"
    ]
  },
  {
    "objectID": "R_basics_dataframes.html#boolean-row-selections",
    "href": "R_basics_dataframes.html#boolean-row-selections",
    "title": "R Basics: data frames and reading simple files",
    "section": "Boolean row selections",
    "text": "Boolean row selections\nHowever, just like we saw with vectors, using logical (boolean) expressions gives us a lot more useful ways of referring to specific values, especially rows. For example, so far we have only peeked at some of the data, and we know that there is a feed called “horsebean”. Maybe we just want to look at only the data for that feed type. We could pull out a subset of the data using this information as follows:\n\nchickwts_horsebeanonly &lt;- chickwts[chickwts$feed %in% \"horsebean\", ]\nnrow(chickwts_horsebeanonly)\n\n[1] 10\n\nprint(chickwts_horsebeanonly)\n\n   grams      feed\n1    179 horsebean\n2    160 horsebean\n3    136 horsebean\n4    227 horsebean\n5    217 horsebean\n6    168 horsebean\n7    108 horsebean\n8    124 horsebean\n9    143 horsebean\n10   140 horsebean\n\n\nIn this way, we created a new data frame that is only the rows from the original data frame where the feed column is “horsebean”, resulting in a data frame that is 10 rows long.\nBut there are a few things in this example I want to unpack:\n\nNote that in the brackets after chickwts, there is a comma, because it’s still [rows, columns].\nThe rows are being selected as the rows where the expression chickwts$feed %in% \"horsebean\" evaluates to TRUE.\nThe columns segment (the part in the brackets after the comma) is blank. Remember that R treats blanks in these dimensions as meaning “everything”. So leaving the columns position blank means “all of the columns.”\nWe could have used the “equals” comparison operator == here instead, like: chickwts$feed == \"horsebean\", but the %in% operator is a little safer, and very useful. We’ll see another example of this shortly.\n\nThis covers the primary ways R has to select certain values and subsets from data frames. We’ll continue to use these throughout, so we’ll get plenty of reminders.",
    "crumbs": [
      "Home",
      "Working with data in R",
      "Data Frames: the most useful data structure in R"
    ]
  },
  {
    "objectID": "R_basics_dataframes.html#range",
    "href": "R_basics_dataframes.html#range",
    "title": "R Basics: data frames and reading simple files",
    "section": "Range",
    "text": "Range\nWe will start exploring statistical distributions in the next unit, but for now, just a few summary statistics will help. First, we would like to know what the limits of the data are, or more precisely, the range. What’s the smallest and largest value in the data set? This can be very informative as we start to think about how to analyze the data.\nTo illustrate this, let’s think about our uncertainty before we look at the data. We know the measurements are in grams, and we know generally that chicks are pretty small animals, but not as small as say, an insect. So we would expect them to be somewhere in the hundreds of grams in order of magnitude. A chick weighing thousands of grams would be several pounds heavy, which would not fit our mental model of a baby chick (at least not my mental model!), and a chick just a few grams heavy would seem to be too small to be born yet. So if we saw values outside our expected range, we may have concerns or questions about the data!\nBut beyond that, what do we expect? Do we think the chick weights will all be relatively close or do we think that some chicks may be twice as heavy or more than others? Think to yourself about this, and consider how sure you feel about it. This step of considering what our assumptions are is a really important step in data analysis! And taking a few seconds to think about what we expect before we use R to check can be a good way to highlight interesting or unexpected results.\nAfter you think about it for a bit, it’s time to actually check. There are a few handy functions in R that will compute a minimum, maximum, or both from a vector of values:\n\nmin(chickwts$grams)\n\n[1] 108\n\nmax(chickwts$grams)\n\n[1] 423\n\nrange(chickwts$grams)\n\n[1] 108 423\n\n\nSo we can see that the chick weights range from about 100 grams to more than 400 grams. We can see that this fits with our most general expectations, and that the weights are not surprisingly large or tiny. But it also tells us that the heaviest chick is more than four times as heavy as the smallest. This may be somewhat surprising. In fact, we may want to double-check that this is not an erroneous outlier, but we will get to that in later units. For now, getting just a simple range has really reduced our uncertainty about the values are in the grams variable.",
    "crumbs": [
      "Home",
      "Working with data in R",
      "Data Frames: the most useful data structure in R"
    ]
  },
  {
    "objectID": "R_basics_dataframes.html#mean-and-median",
    "href": "R_basics_dataframes.html#mean-and-median",
    "title": "R Basics: data frames and reading simple files",
    "section": "Mean and median",
    "text": "Mean and median\nAfter looking at extreme values, the next thing to look at are “central” values. The two most common are the mean and the median. How do we compute these in R? Very easily, now that we know how to get the vector of grams values, because R already has convenient functions for both, and both of these functions expect a vector of numbers.4\n4 I use the “dollar sign” notation in these examples. Can you also get the brackets notation to work, with the same results?\nmean(chickwts$grams)\n\n[1] 261.3099\n\nmedian(chickwts$grams)\n\n[1] 258\n\n\nAnd there you go! Easy peasy. The fact that the two statistics are very close to each other gives us a little more information, as well. The general idea of central values is that all else equal, if we get a new measurement, we would expect it to be close to the central value, which would mean somewhere around 260 grams in this data. We will explore this concept more in the next unit as well.\nFinally, we may want to combine some of these methods to start asking more detailed questions, like, “how do the weights compare between different feeds?” We will eventually get to more sophisticated methods of making these comparisons, but let’s review the tools we have introduced in this tutorial to look at different mean values for two of the feeds:\n\n\nEach of the commented-out lines does the same thing as the line above it (you can uncomment them to check). Take some time to work out how they do the same thing. There’s no real pros or cons to either method, but you may find one easier to read or wrap your head around than the other.\n\nsoybean_weights &lt;- chickwts$grams[chickwts$feed %in% \"soybean\"]\n# soybean_weights &lt;- chickwts[chickwts$feed %in% \"soybean\", \"grams\"]\nsunflower_weights &lt;- chickwts$grams[chickwts$feed %in% \"sunflower\"]\n# sunflower_weights &lt;- chickwts[chickwts$feed %in% \"sunflower\", \"grams\"]\nmean(soybean_weights)\n\n[1] 246.4286\n\nmean(sunflower_weights)\n\n[1] 328.9167\n\n\nLet’s also take a minute to appreciate the usefulness of the %in% operator. So far, we have used it to check for values that equal a certain value, so it would work similar to the comparison operator ==. However, %in% can also be used to check whether the values on the left are a member of the set of things on the right. In other words, if we put a vector of values after the %in% instead of just a single value, we can get TRUE values for multiple matches.\nFor example, the following code gets the mean value for the data where the feed is either soybean or sunflower:5\n5 If you’re reading this tutorial as a web page, you may need to use the scrollbar in the code chunk to see the entire lines.\nsoybean_and_sunflower_weights &lt;- chickwts$grams[chickwts$feed %in% c(\"soybean\", \"sunflower\")]\nmean(soybean_and_sunflower_weights)\n\n[1] 284.5",
    "crumbs": [
      "Home",
      "Working with data in R",
      "Data Frames: the most useful data structure in R"
    ]
  },
  {
    "objectID": "R_order_factors.html",
    "href": "R_order_factors.html",
    "title": "Ordering factors in R",
    "section": "",
    "text": "One common occurrence in data visualization1 is the need to control the ordering of a categorical variable. R provides a lot of ways to analyze and visualize non-numeric variables, but the default is to order these variables alphabetically, and that is rarely the precise ordering one might want.\n1 The issue with ordering shows up in other contexts as well, basically any time you want to analyze ordinal data. For example, being able to change factor levels can be useful for a variety of model-fitting procedures as well.Fortunately, one of R’s core data types is the factor. This data type has been maligned somewhat in the past, to the point that R no longer reads in strings as factors by default. But when you have ordinal categorical data, factors can be indispensable.\nThis tutorial covers two methods of setting the ordering of factor levels, to handle two common occurrences: “manually” setting a relatively small number of levels to s specific order, and setting potentially a large number of levels based on the ordering of a different variable. These are both handy when visualizing data, and are very straightforward once you understand how they work.\nFor example, let’s imagine we did a survey of people’s favorite color and came up with the following:\n\nfavorite_colors &lt;- data.frame(color = c(\"red\", \"orange\", \"yellow\",\n                                        \"green\", \"blue\", \"purple\"),\n                              votes = c(20, 8, 13, 43, 39, 11))\nprint(favorite_colors)\n\n   color votes\n1    red    20\n2 orange     8\n3 yellow    13\n4  green    43\n5   blue    39\n6 purple    11\n\n\nWe can plot these as bars and use the colors themselves to assign the color of bars in a pretty straightforward way. The only trick is that when we are setting the colors of the bars, we need to make sure to (alphabetically) sort those color names, because that’s how R is ordering them by default. This is why “blue” is the first bar displayed and “yellow” is the last.\n\nlibrary(ggplot2)\nggplot(favorite_colors, aes(color, votes)) +\n    geom_col(aes(fill = color)) +\n    scale_fill_manual(values = sort(favorite_colors$color)) +\n    theme_minimal()\n\n\n\n\n\n\n\n\nBut sorting these bars in alphabetical order makes maybe the least sense! So let’s try two different techniques to get two different orderings.",
    "crumbs": [
      "Home",
      "Special topics in R data and graphics",
      "Ordering ordinal variables using factor levels"
    ]
  },
  {
    "objectID": "R_order_factors.html#method-1-setting-an-order-manually",
    "href": "R_order_factors.html#method-1-setting-an-order-manually",
    "title": "Ordering factors in R",
    "section": "Method 1: setting an order manually",
    "text": "Method 1: setting an order manually\nSo now that we see the issue, let’s talk about solutions. The essential issue here is how to set the order of the color factor. One simple way to set factor order is using the factor() function itself. One of the arguments of factor() is levels, and this simply takes a vector of strings, where the order of the strings in the vector sets the order of the levels that match those strings.\nIn our current example, we might want to set the order of the color levels to “rainbow” order. Here’s how we could do that, printing out the levels to demonstrate that the ordering worked.\n\nfavorite_colors$color_rainbow &lt;- factor(favorite_colors$color,\n                                        levels = c(\"red\", \"orange\", \"yellow\",\n                                                   \"green\", \"blue\", \"purple\"))\nlevels(favorite_colors$color_rainbow)\n\n[1] \"red\"    \"orange\" \"yellow\" \"green\"  \"blue\"   \"purple\"\n\n\nTo show how this affects things when we plot the data, let’s first look at a plain bar plot without setting the fill color:\n\nggplot(favorite_colors, aes(color_rainbow, votes)) +\n    geom_col() +\n    theme_minimal()\n\n\n\n\n\n\n\n\nAs you can see, the bars are now ordered along the x-axis according to the factor level order that we specified, instead of alphabetical order.\nAnd now if we’d like to make the fill colors match the labels, we can use levels() to extract those labels, instead of letting R coerce the factor values to integers.\n\nggplot(favorite_colors, aes(color_rainbow, votes)) +\n    geom_col(aes(fill = color_rainbow)) +\n    scale_fill_manual(values = levels(favorite_colors$color_rainbow)) +\n    theme_minimal()\n\n\n\n\n\n\n\n\nSo now the fill values are ordered in our “rainbow” level order, as well as the ordering on the x-axis.",
    "crumbs": [
      "Home",
      "Special topics in R data and graphics",
      "Ordering ordinal variables using factor levels"
    ]
  },
  {
    "objectID": "R_order_factors.html#method-2-ordering-based-on-another-variable",
    "href": "R_order_factors.html#method-2-ordering-based-on-another-variable",
    "title": "Ordering factors in R",
    "section": "Method 2: ordering based on another variable",
    "text": "Method 2: ordering based on another variable\nBeing able to “manually” set the order of factor levels is very powerful, but sometimes you want the order to depend on something else. This is especially the case when you have a lot of levels, like if you have data for every US state, and you want to order the states according to some statistic you are examining.\nTo continue with our hypothetical color survey, we might want our bar chart to be “sorted” in the order of preference, rather than by some other arbitrary order like “rainbow” order. In order to do this, we use the reorder() function, which simply takes a factor (or something able to be coerced into a factor) as the first argument, and then another variable (of the same length) as the second argument, which determines the ranking of the factor levels.\nHere’s what this looks like, and how the resulting plot looks:\n\nfavorite_colors$color_choices &lt;- reorder(favorite_colors$color,\n                                         favorite_colors$votes)\n\nggplot(favorite_colors, aes(color_choices, votes)) +\n    geom_col() +\n    theme_minimal()\n\n\n\n\n\n\n\n\nSo now the smallest value of “votes” aligns with the smallest factor level, and so on. If we would instead like to make the largest value of votes the first level, then we can set the argument decreasing = TRUE.\n\nfavorite_colors$color_choices &lt;- reorder(favorite_colors$color,\n                                         favorite_colors$votes,\n                                         decreasing = TRUE)\n\nggplot(favorite_colors, aes(color_choices, votes)) +\n    geom_col() +\n    theme_minimal()\n\n\n\n\n\n\n\n\nNow if we want to get the colors of the bars back into the plot, we can still use the same trick of setting the order of the values to the level order.\n\nggplot(favorite_colors, aes(color_choices, votes)) +\n    geom_col(aes(fill = color_choices)) +\n    scale_fill_manual(values = levels(favorite_colors$color_choices)) +\n    theme_minimal()\n\n\n\n\n\n\n\n\nHowever, one small nitpick” the order of the fill colors in the legend is the same as the order on the x-axis, but maybe we’d like it to be in “rainbow” order. Here’s one last example, showing that you can “mix and match” a bit, where we can use the factor that’s ordered by the number of votes to set the x-axis order, but then use the factor ordered by our manual “rainbow order” to set the order of the fill values.\n\nggplot(favorite_colors, aes(color_choices, votes)) +\n    geom_col(aes(fill = color_rainbow)) +\n    scale_fill_manual(values = levels(favorite_colors$color_rainbow)) +\n    theme_minimal()",
    "crumbs": [
      "Home",
      "Special topics in R data and graphics",
      "Ordering ordinal variables using factor levels"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "INST462: Introduction to Data Visualization",
    "section": "",
    "text": "What’s on this site\nWelcome! If you are registered for the Fall 2025 session of INST 462 (sections 201-203) at the University of Maryland, with Scott Jackson as your instructor, you are in the right place.\nThis is where I am hosting the main tutorial materials for the course. Specifically, the pages on this site are intended to give you all the details you need in order to complete the weeky Practice exercises and Assignments.\nOther materials like the Practice exercises themselves, weekly Assignments, data files, etc. are available on the official course site on ELMS.\n\n\nHow to use this site\n\nThe navigation is mainly on the left-hand side. The selections are grouped roughly by content themes, but you are encouraged to hop around to review topics as needed.\nOnce you’re on a page, there should be a list of sections on the right hand side to help you navigate. I’m hoping this is helpful when you want to return to a section for review.\nAll of these materials are intended to be read through from beginning to end (though of course you can take breaks). If you try to skip around and read sections out of order, it might not make as much sense.\nI will be adding material and additional resources as we go through the course, so this is still a work in progress.\nThere’s a little toggle in the upper right if you want to switch between light and dark color schemes.\n\n\n\nCode and Code Tutorials\n\nThis site is created using Quarto, which means the pages are mostly written in a flavor of R Markdown.\nThis also means there will be sections of code and results in most of the tutorials.\nYou should be running all of the code yoruself on your own machine as you work through the material.\nYou can either copy & paste the code from this site, or you can just download the .qmd source files, either by cloning this entire repository off of GitHub, or by visiting the course site on ELMS and downloading them from the Modules section of that site."
  },
  {
    "objectID": "R_time_format_plot.html",
    "href": "R_time_format_plot.html",
    "title": "Formatting and plotting time in R",
    "section": "",
    "text": "Time is complicated. More specifically, the way we record and measure time in terms of seconds, minutes, hours, days, weeks, months, years, leap years, and so on can get kind of messy, especially compared to units like those on a standard metric system.\nBut time is an extremely common and important dimension in data analysis, including data visualization. In some kinds of analyses we can get away with some simplifications, like measuring everything in the same unit, like second or days or something like that. But especially in data visualization, we may need to communicate different kinds of cycles, like showing the change across different weeks or months or years.\nIn order to help manage this, this tutorial has two goals. First, I’ll go through a few of the basics of time formats and talk about how to use the lubridate package to convert some of the more common date/time strings into a proper data format. Second, I’ll show you some of the common ways to format time for the purpose of displaying things in plots, like formatting dates on a plot axis.",
    "crumbs": [
      "Home",
      "Special topics in R data and graphics",
      "Time data: formatting and plotting"
    ]
  },
  {
    "objectID": "R_time_format_plot.html#epoch-time",
    "href": "R_time_format_plot.html#epoch-time",
    "title": "Formatting and plotting time in R",
    "section": "Epoch time",
    "text": "Epoch time\nThe first concept to know about is epoch time. In short, one of the simplest ways to represent a specific moment in time, at least for computers, is a simple count of how many seconds have passed since a particular starting point, called an epoch.\nIt turns out that for most systems, there is a standard epoch – sometimes referred to as Unix time – that starts at midnight1 on January 1, 1970, in the UTC time zone.2 So a value of 1 would be one second after midnight on Jan 1, 1970, and so on. In practical terms, this can mean that sometimes if you coerce a datetime value into a numeric value, it will get converted into a large number. For example, midnight of January 1, 2025 is 1,735,689,600 seconds after the beginning of the epoch. So if you think you’re working with a datetime value but you’re seeing values close to a billion, that’s likely an indication that you’re dealing with epoch time, in seconds.\n1 Just to be super clear, by “midnight”, I mean the instant that the date changed from Dec 31, 1969 to Jan 1, 1970. That’s the zero value.2 Another interesting piece of trivia is that “UTC” is an acronym that doesn’t exactly stand for anything, because it represents a compromise. This time zone is the one that corresponds to the UK, and earlier in history it was called “Greenwich Mean Time” (GMT). The UTC label stands for “Coordinated Universal Time” in English, but “Temps Universel Coordonné” in French, and when it was designated as a new universal standard, the organizations responsible wanted the three-letter code to be universal across all languages. So as a compromise, instead of picking CUT or TUC or something based on a specific language, the decision was made to use UTC for all languages.",
    "crumbs": [
      "Home",
      "Special topics in R data and graphics",
      "Time data: formatting and plotting"
    ]
  },
  {
    "objectID": "R_time_format_plot.html#posix",
    "href": "R_time_format_plot.html#posix",
    "title": "Formatting and plotting time in R",
    "section": "POSIX",
    "text": "POSIX\nAnother important acronym to be aware of is POSIX. This refers to a family of standards across many aspects of computing, not just time standards. But in R, some of the datetime classes have “POSIX” in the name, like “POSIXct” or “POSIXt”. This is also related to epoch time (the POSIXct class essentially still captures the values in epoch time), but if you see your time data represented as these classes, that’s good.",
    "crumbs": [
      "Home",
      "Special topics in R data and graphics",
      "Time data: formatting and plotting"
    ]
  },
  {
    "objectID": "R_time_format_plot.html#common-date-string-formats",
    "href": "R_time_format_plot.html#common-date-string-formats",
    "title": "Formatting and plotting time in R",
    "section": "Common date string formats",
    "text": "Common date string formats\nOne of the POSIX standards is a set of common symbols used to represent different kinds of date formats. Think about how many different ways dates can be written in English. For example, the following all refer to the same date:\n\nJanuary 13th, 2025\nJan 13, 2025\n13 Jan 2025\n01/13/2025\n1/13/25\n2025-01-13\n\n… and so on. There are full month names, abbreviations, different orders, different separating characters, etc. etc. So part of what POSIX did was to designate a common set of symbols (characters) that represent these different “chunks” of a written date. In R, these are all preceded by a % as well. Here’s a non-exhaustive list of the most common ones:\n\nDate/day format symbols\n\n\n\nsymbol\nrepresents\n\n\n\n\n%d\nday of the month with a leading zero (01, 02, 03 … 31)\n\n\n%e\nday of the month without a leading zero (1, 2, 3 … 31)\n\n\n%m\nnumeric month (01-12)\n\n\n%b\nabbreviated month name (Jan, Feb … Dec)\n\n\n%B\nfull month name (January, February … Dec)\n\n\n%y\nyear, last two digits (00-99)\n\n\n%Y\nyear, four digits (0000-9999)\n\n\n%a\nabbreviated day of the week (Sun-Sat)3\n\n\n%A\nfull day of the week (Sunday-Saturday)\n\n\n%w\nweekday as a number, where 0 is Sunday\n\n\n%j\nday of the year (1-366)\n\n\n\n3 Just by the way, some systems also represent day of the week as an integer, and depending on the system, locale, or other settings, day 1 might be Sunday or Monday. Sunday is probably the most common default.\n\nTime format symbols\n\n\n\n\n\n\n\nsymbol\nrepresents\n\n\n\n\n%H\nhour in 24-hour format (00-23)\n\n\n%I\nhour in 12-hour format, with leading zero (01, 02 … 12)\n\n\n%i\nhour in 12-hour format, no leading zero (1, 2 … 12)\n\n\n%p\nAM/PM\n\n\n%M\nminute\n\n\n%S\nsecond\n\n\n%Z\ntime zone name (UTC, etc.)\n\n\n%z\nUTC offset (+/- HHHH)\n\n\n\n\n\nLocales\nString formatting of time also depends on the locale (sometimes also called localization), which is a technical term that is used to distinguish what are either different geographic or linguistic regions. For example, the month names and abbreviations are obviously different in English, Spanish, and Chinese. Bit the format symbols above are still correct. So the precise output is a combination of the format strings used, interpreted according to the locale of the machine producing the output.",
    "crumbs": [
      "Home",
      "Special topics in R data and graphics",
      "Time data: formatting and plotting"
    ]
  },
  {
    "objectID": "R_time_format_plot.html#the-basic-problem",
    "href": "R_time_format_plot.html#the-basic-problem",
    "title": "Formatting and plotting time in R",
    "section": "The basic problem",
    "text": "The basic problem\nDespite all of the standards discussed above, whenever you come across data that contains times, dates, or datetimes, it’s rarely predictable what exact format it will take. Converting what are typically strings of text into proper datetime objects is a necessary step for analysis, including visualization, but since the string formats can have a wide variety of forms, there can’t be a simple uniform solution.4\n4 One example of an “unsolvable” challenge for a simple algorithm would be when you are looking at date ranges that are ambiguous in terms of numerical values for days/months/years. For example, given a string like “09-03-12”, American conventions of month-day-year would indicate September 3, 2012, European conventions of day-month-year would indicate March 9, 2012, but it’s also possible it could be in descending order of year-month-day, indicating March 12, 2009. Knowledge of the source of the data or the intended date range might be needed to disambiguate something like this.This means that the best solution might me to provide a tool for analysts that they can use to apply their own judgment on the structure of the format, to easily convert from “families” of similar string formats into a proper data format.",
    "crumbs": [
      "Home",
      "Special topics in R data and graphics",
      "Time data: formatting and plotting"
    ]
  },
  {
    "objectID": "R_time_format_plot.html#the-lubridate-easy-button",
    "href": "R_time_format_plot.html#the-lubridate-easy-button",
    "title": "Formatting and plotting time in R",
    "section": "The lubridate easy button",
    "text": "The lubridate easy button\nFor this purpose, the lubridate package is a gift, besides being one of the best-named R packages of all time.5 This package provides a number of capabilities for enhancing how R treats datetime objects, but one of the best is its family of {ymd}_{hms}() functions.\n5 In my mind, the cleverness of the lubridate name is second only to the referential genius of the magrittr package.In short, lubridate has a series of functions whose function names serve essentially as a shorthand for different datetime format string patterns. For example, the ymd_hms() function takes a string that follows the “YearMonthDay_HourMinuteSecond” format, handling all varieties of different abbreviations, leading zeros, separating strings, AM/PM or 24-hour formats, and so on. But even better, there are different versions of these functions that simply differ in the order of the characters in the function name, to indicate different orderings in the format string. Additionally, the underscore is optional, so that you can use either “half” of the sequence to format simple dates or simple times.\nSee the examples below:\n\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\nprint(ymd_hms(\"2015-09-22 13:22:45\"))\n\n[1] \"2015-09-22 13:22:45 UTC\"\n\nprint(ymd_hms(\"2015-09-22 1:22:45 PM\"))\n\n[1] \"2015-09-22 13:22:45 UTC\"\n\nprint(ymd_hm(\"2015-09-22 13:22\"))\n\n[1] \"2015-09-22 13:22:00 UTC\"\n\nprint(ymd_h(\"2015-09-22 1PM\"))\n\n[1] \"2015-09-22 13:00:00 UTC\"\n\nprint(mdy_hm(\"Sep 22, 2015 13:22\"))\n\n[1] \"2015-09-22 13:22:00 UTC\"\n\nprint(mdy_hm(\"Sep 22nd, 2015 13:22\"))\n\n[1] \"2015-09-22 13:22:00 UTC\"\n\nprint(mdy_h(\"09/22/15 1PM\"))\n\n[1] \"2015-09-22 13:00:00 UTC\"\n\nprint(mdy(\"09/22/15\"))\n\n[1] \"2015-09-22\"\n\nprint(hms(\"The event took 10 hours, 13 minutes, and 45 seconds\"))\n\n[1] \"10H 13M 45S\"\n\nprint(hm(\"1:13 PM\"))\n\n[1] \"1H 13M 0S\"\n\n\nThe final example shows that the {hms}() functions parse strings into “period component” objects, not strictly “time of day”-type objects. This means they do not manage AM/PM, so if you wanted to compute/plot differences or progressions in the hours of the day, you would need to use a 24-hour format.\nBut with all of the datetime functions that include some part of a {ymd} component, tey handle a wide variety of string formats without the need to refer to the nitty-gritty of the POSIX standard formatting strings described above.\nIn short, if your task is to simply take datetime data represented in some kind of string format and convert those strings into proper datetime objects, the {ymd}_{hms}() family of functions make that incredibly easy.",
    "crumbs": [
      "Home",
      "Special topics in R data and graphics",
      "Time data: formatting and plotting"
    ]
  }
]